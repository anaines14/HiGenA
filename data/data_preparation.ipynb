{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alloy4Fun Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os \n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import jpype # Java\n",
    "import re # Regular expression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 9jPK8KBWzjFmBx4Hb.json.\n",
      "Imported aTwuoJgesSd8hXXEP.json.\n",
      "Imported bNCCf9FMRZoxqobfX.json.\n",
      "Imported dkZH6HJNQNLLDX6Aj.json.\n",
      "Imported FwCGymHmbqcziisH5.json.\n",
      "Imported gAeD3MTGCCv8YNTaK.json.\n",
      "Imported JC8Tij8o8GZb99gEJ.json.\n",
      "Imported JDKw8yJZF5fiP3jv3.json.\n",
      "Imported jyS8Bmceejj9pLbTW.json.\n",
      "Imported PQAJE67kz8w5NWJuM.json.\n",
      "Imported PSqwzYAfW9dFAa9im.json.\n",
      "Imported QxGnrFQnXPGh2Lh8C.json.\n",
      "Imported sDLK7uBCbgZon3znd.json.\n",
      "Imported WGdhwKZnCu7aKhXq9.json.\n",
      "Imported YH3ANm7Y5Qe5dSYem.json.\n",
      "Imported zoEADeCW2b2suJB2k.json.\n",
      "Imported zRAn69AocpkmxXZnW.json.\n"
     ]
    }
   ],
   "source": [
    "def importDataFromDir(dir):\n",
    "    # Import all the data from a directory\n",
    "    # dir: directory with the data\n",
    "    # return: a dictionary of dataframes\n",
    "    dict = {}\n",
    "\n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith('.json'):\n",
    "            df = pd.read_json(f'{dir}/' + file, lines=True)\n",
    "            dict[file.removesuffix(\".json\")] = df\n",
    "            print(f\"Imported {file}.\")\n",
    "\n",
    "    return dict\n",
    "\n",
    "def removeFile(file):\n",
    "    # Remove the log file\n",
    "    try:\n",
    "        os.remove(file)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "# Remove the log file if exists\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "log_file_ast = \"logs/astError.txt\"\n",
    "log_file_drops = \"logs/drops.txt\"\n",
    "removeFile(log_file_ast)\n",
    "removeFile(log_file_drops)\n",
    "\n",
    "# Import files from the data directory\n",
    "dict = importDataFromDir('datasets/submissions')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate challenge code from the rest of submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_c</th>\n",
       "      <th>cmd_i</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>original</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>msg</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>cAMmPjLAFceP7dnod</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-31 10:28:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id  cmd_c  cmd_i  cmd_n  \\\n",
       "0  9jPK8KBWzjFmBx4Hb    NaN    NaN    NaN   \n",
       "\n",
       "                                                code       derivationOf  \\\n",
       "0  /**\\n * Linear temporal logic revision exercis...  cAMmPjLAFceP7dnod   \n",
       "\n",
       "            original  sat                 time  msg  \\\n",
       "0  9jPK8KBWzjFmBx4Hb  NaN  2019-10-31 10:28:19  NaN   \n",
       "\n",
       "                                               theme  \n",
       "0  {'currentFramePosition': {}, 'currentlyProject...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separateChallengeRows(dict):\n",
    "    # Separate the original row of each dataframe\n",
    "    # dict: dictionary of dataframes\n",
    "    # return: a dictionary of dataframes\n",
    "    challengeRows = {}\n",
    "\n",
    "    for key, df in dict.items():\n",
    "        # Store the index of the original row of each dataframe\n",
    "        index = df[df[\"_id\"] == key].index.values.astype(int)[0]\n",
    "        row = df.iloc[index]\n",
    "        # store the original row in a new dataframe\n",
    "        challengeRows[key] = pd.DataFrame([row.values], columns=row.index)\n",
    "        # Remove the original row from the dataframe\n",
    "        df.drop(index=index, inplace=True)\n",
    "\n",
    "    return challengeRows\n",
    "\n",
    "challengeRows = separateChallengeRows(dict) \n",
    "\n",
    "# Check\n",
    "challengeRows[\"9jPK8KBWzjFmBx4Hb\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                0\n",
       "cmd_c            926\n",
       "cmd_i             36\n",
       "cmd_n            926\n",
       "code               0\n",
       "derivationOf       0\n",
       "original           0\n",
       "sat               36\n",
       "time               0\n",
       "msg             4368\n",
       "theme           5242\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = dict[\"9jPK8KBWzjFmBx4Hb\"]\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features meaning:\n",
    "- _id: the id of the interaction\n",
    "- time: the timestamp of its creation\n",
    "- derivationOf: the parent entry\n",
    "- original: the first ancestor with secrets (always the same within an exercise)\n",
    "- code: the complete code of the model (excluding the secrets defined in the original entry) (with student comments removed)\n",
    "- sat: whether the command was satisfiable (counter-example found for checks), or -1 when error thrown [only for executions]\n",
    "- cmd_i: the index of the executed command [only for executions]\n",
    "- cmd_n: the name of the executed command [only for successful executions, i.e. no error thrown]\n",
    "- cmd_c: whether the command was a check [only for successful executions, i.e. no error thrown]\n",
    "- msg: the error or warning message [only for successful executions with warnings or when error thrown]\n",
    "- theme: the visualisation theme [only for sharing entries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cmd_i null values\n",
    "\n",
    "cmd_i is null for non-executions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_c</th>\n",
       "      <th>cmd_i</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>original</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>msg</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>P3gFuEkajduWTyFeo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>6YmxWkc8PtXEqdafi</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-31 11:47:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>K2ejbWj7HT3mSFdym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>4zDygwoYWF7AAqHv8</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-1-3 13:48:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2MPKwEJXDud4Ro8Ka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-2-1 18:47:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>MdZs9uee25QgFwvi7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>kb8KrpANCxg9XXcLs</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-31 11:48:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>fWKpSLkdPZPxkSoJe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>8KGv5F6b8ySPofNdJ</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-31 11:52:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id  cmd_c  cmd_i cmd_n  \\\n",
       "32   P3gFuEkajduWTyFeo    NaN    NaN   NaN   \n",
       "159  K2ejbWj7HT3mSFdym    NaN    NaN   NaN   \n",
       "210  2MPKwEJXDud4Ro8Ka    NaN    NaN   NaN   \n",
       "302  MdZs9uee25QgFwvi7    NaN    NaN   NaN   \n",
       "338  fWKpSLkdPZPxkSoJe    NaN    NaN   NaN   \n",
       "\n",
       "                                                  code       derivationOf  \\\n",
       "32   /**\\n * Linear temporal logic revision exercis...  6YmxWkc8PtXEqdafi   \n",
       "159  /**\\n * Linear temporal logic revision exercis...  4zDygwoYWF7AAqHv8   \n",
       "210  /**\\n * Linear temporal logic revision exercis...  9jPK8KBWzjFmBx4Hb   \n",
       "302  /**\\n * Linear temporal logic revision exercis...  kb8KrpANCxg9XXcLs   \n",
       "338  /**\\n * Linear temporal logic revision exercis...  8KGv5F6b8ySPofNdJ   \n",
       "\n",
       "              original  sat                 time  msg  \\\n",
       "32   9jPK8KBWzjFmBx4Hb  NaN  2019-10-31 11:47:23  NaN   \n",
       "159  9jPK8KBWzjFmBx4Hb  NaN    2020-1-3 13:48:36  NaN   \n",
       "210  9jPK8KBWzjFmBx4Hb  NaN    2022-2-1 18:47:26  NaN   \n",
       "302  9jPK8KBWzjFmBx4Hb  NaN  2019-10-31 11:48:12  NaN   \n",
       "338  9jPK8KBWzjFmBx4Hb  NaN  2019-10-31 11:52:15  NaN   \n",
       "\n",
       "                                                 theme  \n",
       "32   {'currentFramePosition': {}, 'currentlyProject...  \n",
       "159  {'currentFramePosition': {}, 'currentlyProject...  \n",
       "210  {'currentFramePosition': {}, 'currentlyProject...  \n",
       "302  {'currentFramePosition': {}, 'currentlyProject...  \n",
       "338  {'currentFramePosition': {}, 'currentlyProject...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows with cmd_i = null\n",
    "nullDF = df1[df1[\"cmd_i\"].isnull()]\n",
    "nullDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with cmd_i null:  36\n",
      "Rows with sat null:  36\n",
      "Rows with cmd_c null :  36\n",
      "Rows with cmd_n null :  36\n",
      "Rows with theme null :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows with cmd_i null: \", len(nullDF))\n",
    "print(\"Rows with sat null: \", len(nullDF[nullDF[\"sat\"].isnull()]))\n",
    "print(\"Rows with cmd_c null : \", len(nullDF[nullDF[\"cmd_c\"].isnull()]))\n",
    "print(\"Rows with cmd_n null : \", len(nullDF[nullDF[\"cmd_n\"].isnull()]))\n",
    "print(\"Rows with theme null : \", len(nullDF[nullDF[\"theme\"].isnull()]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever cmd_i is null it means that there was no execution. It is the sharing of a model. This cases might be irrelevant to the problem so they can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows dropped: 1342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_c</th>\n",
       "      <th>cmd_i</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>original</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>msg</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_id, cmd_c, cmd_i, cmd_n, code, derivationOf, original, sat, time, msg, theme]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logDrop(id, reason):\n",
    "    # Log an error\n",
    "    # id: id of the submission\n",
    "    # challenge: id of the challenge\n",
    "    # error: error message\n",
    "    # expr: expression that failed\n",
    "    file = open(log_file_drops, \"a\")\n",
    "    file.write(\"DROPPED \" + id + \" FOR \" + reason + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "def shortCircuit(df, index):\n",
    "    # Short circuit the derivation of a row.\n",
    "    # If A derives B and B derives C, then A derives C and B is removed.\n",
    "    # df: dataframe\n",
    "    # index: index of the row to be removed\n",
    "    # return: dataframe with the row short circuited\n",
    "\n",
    "    # Get row information\n",
    "    row = df.loc[[index]]\n",
    "    id = row[\"_id\"].values[0]\n",
    "    derivation = row[\"derivationOf\"].values[0]\n",
    "\n",
    "    # Remove row\n",
    "    df.drop(index, inplace=True)\n",
    "\n",
    "    # Short circuit derivations\n",
    "    df.loc[df[\"derivationOf\"] == id, \"derivationOf\"] = derivation\n",
    "\n",
    "    return df\n",
    "\n",
    "def dropNulls(dict, col):\n",
    "    # Remove rows with col null\n",
    "    # dict: dictionary of dataframes\n",
    "    # return: dataframe with rows with col null removed\n",
    "    total = 0\n",
    "    for challengeID, df in dict.items():\n",
    "        # Filter rows with col= null\n",
    "        nullDF = df[df[col].isnull()]\n",
    "        # Short circuit derivations\n",
    "        for index, row in nullDF.iterrows():\n",
    "            df = shortCircuit(df, index)\n",
    "            logDrop(row[\"_id\"], \"having null \" + col)\n",
    "            total += 1            \n",
    "    print(f\"Total number of rows dropped: {total}\")\n",
    "    return dict\n",
    "\n",
    "\n",
    "# Drop rows with cmd_i null\n",
    "dict = dropNulls(dict, \"cmd_i\")\n",
    "# Check results\n",
    "df1 = dict[\"9jPK8KBWzjFmBx4Hb\"]\n",
    "nullDF = df1[df1[\"cmd_i\"].isnull()]\n",
    "nullDF.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cmd_c and cmd_n null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_c</th>\n",
       "      <th>cmd_i</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>original</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>msg</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nuWnon2d7N7N7ZFvw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>ZjxPhwuLGd52cZyox</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2020-11-23 23:09:43</td>\n",
       "      <td>There are 1 possible tokens that can appear he...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sxuHvWgfPeRh9QYYy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>RBovdMdE7s7k2Z3xY</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2020-12-1 21:46:47</td>\n",
       "      <td>There are 37 possible tokens that can appear h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xPeTe3FdpxzspZTta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>t45BxKKpdXbYN4Aun</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2020-11-26 10:17:06</td>\n",
       "      <td>There are 1 possible tokens that can appear he...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GQbQyxLarysc73gH7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>2js6dSN2dk4HhJmbF</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2020-12-1 11:39:04</td>\n",
       "      <td>There are 37 possible tokens that can appear h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CCt6wniT5St2hKKFr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-10-31 10:48:50</td>\n",
       "      <td>There are 29 possible tokens that can appear h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  _id  cmd_c  cmd_i cmd_n  \\\n",
       "13  nuWnon2d7N7N7ZFvw    NaN    7.0   NaN   \n",
       "14  sxuHvWgfPeRh9QYYy    NaN    7.0   NaN   \n",
       "16  xPeTe3FdpxzspZTta    NaN    7.0   NaN   \n",
       "20  GQbQyxLarysc73gH7    NaN    3.0   NaN   \n",
       "25  CCt6wniT5St2hKKFr    NaN    0.0   NaN   \n",
       "\n",
       "                                                 code       derivationOf  \\\n",
       "13  /**\\n * Linear temporal logic revision exercis...  ZjxPhwuLGd52cZyox   \n",
       "14  /**\\n * Linear temporal logic revision exercis...  RBovdMdE7s7k2Z3xY   \n",
       "16  /**\\n * Linear temporal logic revision exercis...  t45BxKKpdXbYN4Aun   \n",
       "20  /**\\n * Linear temporal logic revision exercis...  2js6dSN2dk4HhJmbF   \n",
       "25  /**\\n * Linear temporal logic revision exercis...  9jPK8KBWzjFmBx4Hb   \n",
       "\n",
       "             original  sat                 time  \\\n",
       "13  9jPK8KBWzjFmBx4Hb -1.0  2020-11-23 23:09:43   \n",
       "14  9jPK8KBWzjFmBx4Hb -1.0   2020-12-1 21:46:47   \n",
       "16  9jPK8KBWzjFmBx4Hb -1.0  2020-11-26 10:17:06   \n",
       "20  9jPK8KBWzjFmBx4Hb -1.0   2020-12-1 11:39:04   \n",
       "25  9jPK8KBWzjFmBx4Hb -1.0  2019-10-31 10:48:50   \n",
       "\n",
       "                                                  msg theme  \n",
       "13  There are 1 possible tokens that can appear he...   NaN  \n",
       "14  There are 37 possible tokens that can appear h...   NaN  \n",
       "16  There are 1 possible tokens that can appear he...   NaN  \n",
       "20  There are 37 possible tokens that can appear h...   NaN  \n",
       "25  There are 29 possible tokens that can appear h...   NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows with cmd_c = null\n",
    "nullDF = df1[df1[\"cmd_c\"].isnull()]\n",
    "nullDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with cmd_c null:  890\n",
      "Rows with cmd_n null:  890\n",
      "Rows with msg null:  0\n",
      "Rows with negative sat:  890\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows with cmd_c null: \", len(nullDF))\n",
    "print(\"Rows with cmd_n null: \", len(nullDF[nullDF[\"cmd_n\"].isnull()]))\n",
    "print(\"Rows with msg null: \", len(nullDF[nullDF[\"msg\"].isnull()]))\n",
    "print(\"Rows with negative sat: \", len(nullDF[nullDF[\"sat\"] == -1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever cmd_c is null, cmd_n is also null. These values are null for cases where a syntactic error is thrown and a msg appears.\n",
    "The code in these case is not parseable. We can drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows dropped: 28066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_id                0\n",
       "cmd_c              0\n",
       "cmd_i              0\n",
       "cmd_n              0\n",
       "code               0\n",
       "derivationOf       0\n",
       "original           0\n",
       "sat                0\n",
       "time               0\n",
       "msg             4332\n",
       "theme           4352\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with cmd_c null\n",
    "dict = dropNulls(dict, \"cmd_c\")\n",
    "# Check results\n",
    "dict[\"9jPK8KBWzjFmBx4Hb\"].isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with mgs and theme null values is not important in these context."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove extra features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cmd_c feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 68284, 0.0: 46})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def countValues(dict, col):\n",
    "    # Count the values in a column\n",
    "    # df: dataframe\n",
    "    # col: column to count\n",
    "    # return: dataframe with the counts\n",
    "    totalCount = collections.Counter()\n",
    "\n",
    "    for df in dict.values():\n",
    "        count = df[col].value_counts().to_dict()\n",
    "        totalCount.update(count)        \n",
    "\n",
    "    return totalCount\n",
    "\n",
    "# Count the different values in the cmd_c column across all the dataframes\n",
    "counter = countValues(dict, 'cmd_c')\n",
    "print(counter)\n",
    "\n",
    "plt.barh([str(k) for k in counter.keys()], counter.values())\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of 0 values for the column cmd_c is irrelevant (when the executed command is not a check). For that reason, entries with these values should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows dropped: 46\n",
      "Counter({1.0: 68284})\n"
     ]
    }
   ],
   "source": [
    "def dropNonChecks(dict):\n",
    "    # Drop the rows that are not checks\n",
    "    # dict: dictionary of dataframes\n",
    "    # return: dataframe with the rows that are not checks removed\n",
    "    total = 0\n",
    "    for df in dict.values():\n",
    "        # Filter rows with cmd_c != 0\n",
    "        dfToDrop = df[df[\"cmd_c\"] == 0]\n",
    "        # Short circuit derivations\n",
    "        for index, row in dfToDrop.iterrows():\n",
    "            df = shortCircuit(df, index)\n",
    "            logDrop(row[\"_id\"], \"being a non check (cmd_c = 0)\")\n",
    "            total += 1\n",
    "    print(f\"Total number of rows dropped: {total}\")\n",
    "    return dict\n",
    "\n",
    "# Remove the rows with the value 0 in the cmd_c column\n",
    "dropNonChecks(dict)\n",
    "\n",
    "# Check\n",
    "print(countValues(dict, 'cmd_c'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9jPK8KBWzjFmBx4Hb': 4352}\n",
      "{'aTwuoJgesSd8hXXEP': 2392}\n",
      "{'bNCCf9FMRZoxqobfX': 3660}\n",
      "{'dkZH6HJNQNLLDX6Aj': 14934}\n",
      "{'FwCGymHmbqcziisH5': 982}\n",
      "{'gAeD3MTGCCv8YNTaK': 2476}\n",
      "{'JC8Tij8o8GZb99gEJ': 854}\n",
      "{'JDKw8yJZF5fiP3jv3': 5055}\n",
      "{'jyS8Bmceejj9pLbTW': 600}\n",
      "{'PQAJE67kz8w5NWJuM': 3056}\n",
      "{'PSqwzYAfW9dFAa9im': 9851}\n",
      "{'QxGnrFQnXPGh2Lh8C': 6388}\n",
      "{'sDLK7uBCbgZon3znd': 2709}\n",
      "{'WGdhwKZnCu7aKhXq9': 283}\n",
      "{'YH3ANm7Y5Qe5dSYem': 4374}\n",
      "{'zoEADeCW2b2suJB2k': 2072}\n",
      "{'zRAn69AocpkmxXZnW': 4246}\n"
     ]
    }
   ],
   "source": [
    "def operateDFs(dict, op, arg):\n",
    "    # Operate on each dataframe in a dictionary\n",
    "    # dict: dictionary of dataframes\n",
    "    # op: operation to perform\n",
    "    # arg: argument to pass to the operation\n",
    "    for df in dict.values():\n",
    "        op(df, arg)\n",
    "\n",
    "# Count the different values for the original column for each dataframe\n",
    "countValuesOp = (lambda df, arg: print(df[arg].value_counts().to_dict()))\n",
    "operateDFs(dict, countValuesOp, 'original')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every dataframe has the same value for the original column. This column is irrelevant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will drop the irrelevant columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zKAYz8BCDmHKgNoSx</td>\n",
       "      <td>prop8Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>dvhCng5AdxC8MqjFy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-13 23:28:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8FmQ9PNWT2SXncTxX</td>\n",
       "      <td>prop10Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>5eT7wTw5kT8DwTbu2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-11-11 21:54:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eyGu5DYCrnk58G2fJ</td>\n",
       "      <td>prop7Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>niLmMRmm94Hz6ymcD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-1 11:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbr9Aq6WfBLHrvE8</td>\n",
       "      <td>prop19Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>DnAm62D7JaqDzyy5y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-11-26 10:33:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNegade3hLiutxCru</td>\n",
       "      <td>prop11Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>cjK4u23ZAfYm8fatA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-1-19 17:06:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id     cmd_n  \\\n",
       "0  zKAYz8BCDmHKgNoSx   prop8Ok   \n",
       "1  8FmQ9PNWT2SXncTxX  prop10Ok   \n",
       "2  eyGu5DYCrnk58G2fJ   prop7Ok   \n",
       "3  Akbr9Aq6WfBLHrvE8  prop19Ok   \n",
       "4  MNegade3hLiutxCru  prop11Ok   \n",
       "\n",
       "                                                code       derivationOf  sat  \\\n",
       "0  /**\\n * Linear temporal logic revision exercis...  dvhCng5AdxC8MqjFy  1.0   \n",
       "1  /**\\n * Linear temporal logic revision exercis...  5eT7wTw5kT8DwTbu2  1.0   \n",
       "2  /**\\n * Linear temporal logic revision exercis...  niLmMRmm94Hz6ymcD  1.0   \n",
       "3  /**\\n * Linear temporal logic revision exercis...  DnAm62D7JaqDzyy5y  1.0   \n",
       "4  /**\\n * Linear temporal logic revision exercis...  cjK4u23ZAfYm8fatA  1.0   \n",
       "\n",
       "                  time  \n",
       "0  2020-12-13 23:28:11  \n",
       "1  2019-11-11 21:54:33  \n",
       "2   2020-12-1 11:55:11  \n",
       "3  2020-11-26 10:33:29  \n",
       "4   2020-1-19 17:06:22  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns that are not needed\n",
    "dropColOp = (lambda df, arg: df.drop(columns=arg, axis=1, inplace=True))\n",
    "colsToDrop = [\"cmd_c\", \"cmd_i\", \"original\", \"msg\", \"theme\"]\n",
    "\n",
    "operateDFs(dict, dropColOp, colsToDrop)\n",
    "operateDFs(challengeRows, dropColOp, colsToDrop) \n",
    "\n",
    "dict[\"9jPK8KBWzjFmBx4Hb\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code cleaning\n",
    "\n",
    "The code in this dataset comes with comments that can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zKAYz8BCDmHKgNoSx</td>\n",
       "      <td>prop8Ok</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>dvhCng5AdxC8MqjFy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-13 23:28:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8FmQ9PNWT2SXncTxX</td>\n",
       "      <td>prop10Ok</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>5eT7wTw5kT8DwTbu2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-11-11 21:54:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eyGu5DYCrnk58G2fJ</td>\n",
       "      <td>prop7Ok</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>niLmMRmm94Hz6ymcD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-1 11:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbr9Aq6WfBLHrvE8</td>\n",
       "      <td>prop19Ok</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>DnAm62D7JaqDzyy5y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-11-26 10:33:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNegade3hLiutxCru</td>\n",
       "      <td>prop11Ok</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>cjK4u23ZAfYm8fatA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-1-19 17:06:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id     cmd_n  \\\n",
       "0  zKAYz8BCDmHKgNoSx   prop8Ok   \n",
       "1  8FmQ9PNWT2SXncTxX  prop10Ok   \n",
       "2  eyGu5DYCrnk58G2fJ   prop7Ok   \n",
       "3  Akbr9Aq6WfBLHrvE8  prop19Ok   \n",
       "4  MNegade3hLiutxCru  prop11Ok   \n",
       "\n",
       "                                                code       derivationOf  sat  \\\n",
       "0  var sig File { var link : lone File } var sig ...  dvhCng5AdxC8MqjFy  1.0   \n",
       "1  var sig File { var link : lone File } var sig ...  5eT7wTw5kT8DwTbu2  1.0   \n",
       "2  var sig File { var link : lone File } var sig ...  niLmMRmm94Hz6ymcD  1.0   \n",
       "3  var sig File { var link : lone File } var sig ...  DnAm62D7JaqDzyy5y  1.0   \n",
       "4  var sig File { var link : lone File } var sig ...  cjK4u23ZAfYm8fatA  1.0   \n",
       "\n",
       "                  time  \n",
       "0  2020-12-13 23:28:11  \n",
       "1  2019-11-11 21:54:33  \n",
       "2   2020-12-1 11:55:11  \n",
       "3  2020-11-26 10:33:29  \n",
       "4   2020-1-19 17:06:22  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanCode(code):\n",
    "    # Remove comments and empty lines\n",
    "    # code: string with the code\n",
    "    # return: string with the code without comments and empty lines\n",
    "    code = re.sub(r\"(/\\*(.|\\n)*?\\*/)|(//.*)|(--.*)\", \"\", code) # remove comments\n",
    "    code = re.sub(r\"\\n\\n(?=\\n)\", \"\", code) # remove empty lines\n",
    "    code = code.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "    \n",
    "    return \" \".join(code.split()).strip()\n",
    "\n",
    "def applyToCol(df, col, op):\n",
    "    # Apply an operation to a column\n",
    "    # df: dataframe\n",
    "    # col: column to apply the operation\n",
    "    # op: operation to apply\n",
    "    # return: dataframe with the operation applied\n",
    "    df[col] = df[col].apply(op)\n",
    "    return df\n",
    "\n",
    "# Clean the code column\n",
    "cleanCodeOp = (lambda df, arg: applyToCol(df, arg, cleanCode))\n",
    "operateDFs(dict, cleanCodeOp, \"code\")\n",
    "operateDFs(challengeRows, cleanCodeOp, \"code\")\n",
    "\n",
    "df1.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cmd_n rename\n",
    "\n",
    "Rename cmd_n so that it equals the predicate completed by the student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zKAYz8BCDmHKgNoSx</td>\n",
       "      <td>prop8</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>dvhCng5AdxC8MqjFy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-13 23:28:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8FmQ9PNWT2SXncTxX</td>\n",
       "      <td>prop10</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>5eT7wTw5kT8DwTbu2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-11-11 21:54:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eyGu5DYCrnk58G2fJ</td>\n",
       "      <td>prop7</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>niLmMRmm94Hz6ymcD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-1 11:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbr9Aq6WfBLHrvE8</td>\n",
       "      <td>prop19</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>DnAm62D7JaqDzyy5y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-11-26 10:33:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNegade3hLiutxCru</td>\n",
       "      <td>prop11</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>cjK4u23ZAfYm8fatA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-1-19 17:06:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id   cmd_n  \\\n",
       "0  zKAYz8BCDmHKgNoSx   prop8   \n",
       "1  8FmQ9PNWT2SXncTxX  prop10   \n",
       "2  eyGu5DYCrnk58G2fJ   prop7   \n",
       "3  Akbr9Aq6WfBLHrvE8  prop19   \n",
       "4  MNegade3hLiutxCru  prop11   \n",
       "\n",
       "                                                code       derivationOf  sat  \\\n",
       "0  var sig File { var link : lone File } var sig ...  dvhCng5AdxC8MqjFy  1.0   \n",
       "1  var sig File { var link : lone File } var sig ...  5eT7wTw5kT8DwTbu2  1.0   \n",
       "2  var sig File { var link : lone File } var sig ...  niLmMRmm94Hz6ymcD  1.0   \n",
       "3  var sig File { var link : lone File } var sig ...  DnAm62D7JaqDzyy5y  1.0   \n",
       "4  var sig File { var link : lone File } var sig ...  cjK4u23ZAfYm8fatA  1.0   \n",
       "\n",
       "                  time  \n",
       "0  2020-12-13 23:28:11  \n",
       "1  2019-11-11 21:54:33  \n",
       "2   2020-12-1 11:55:11  \n",
       "3  2020-11-26 10:33:29  \n",
       "4   2020-1-19 17:06:22  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeExtraSuffix(pred):\n",
    "    return re.sub(\"OK|Ok|ok\", \"\", pred)\n",
    "\n",
    "remSuffixOp = (lambda df, arg: applyToCol(df, arg, removeExtraSuffix))\n",
    "operateDFs(dict, remSuffixOp, \"cmd_n\")\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year column "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract year from time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zKAYz8BCDmHKgNoSx</td>\n",
       "      <td>prop8</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>dvhCng5AdxC8MqjFy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-13 23:28:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8FmQ9PNWT2SXncTxX</td>\n",
       "      <td>prop10</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>5eT7wTw5kT8DwTbu2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-11-11 21:54:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eyGu5DYCrnk58G2fJ</td>\n",
       "      <td>prop7</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>niLmMRmm94Hz6ymcD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-1 11:55:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbr9Aq6WfBLHrvE8</td>\n",
       "      <td>prop19</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>DnAm62D7JaqDzyy5y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-11-26 10:33:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNegade3hLiutxCru</td>\n",
       "      <td>prop11</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>cjK4u23ZAfYm8fatA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-1-19 17:06:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id   cmd_n  \\\n",
       "0  zKAYz8BCDmHKgNoSx   prop8   \n",
       "1  8FmQ9PNWT2SXncTxX  prop10   \n",
       "2  eyGu5DYCrnk58G2fJ   prop7   \n",
       "3  Akbr9Aq6WfBLHrvE8  prop19   \n",
       "4  MNegade3hLiutxCru  prop11   \n",
       "\n",
       "                                                code       derivationOf  sat  \\\n",
       "0  var sig File { var link : lone File } var sig ...  dvhCng5AdxC8MqjFy  1.0   \n",
       "1  var sig File { var link : lone File } var sig ...  5eT7wTw5kT8DwTbu2  1.0   \n",
       "2  var sig File { var link : lone File } var sig ...  niLmMRmm94Hz6ymcD  1.0   \n",
       "3  var sig File { var link : lone File } var sig ...  DnAm62D7JaqDzyy5y  1.0   \n",
       "4  var sig File { var link : lone File } var sig ...  cjK4u23ZAfYm8fatA  1.0   \n",
       "\n",
       "                  time  \n",
       "0  2020-12-13 23:28:11  \n",
       "1  2019-11-11 21:54:33  \n",
       "2   2020-12-1 11:55:11  \n",
       "3  2020-11-26 10:33:29  \n",
       "4   2020-1-19 17:06:22  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict[\"9jPK8KBWzjFmBx4Hb\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractYear(date):\n",
    "    # Extract the year and month from a date\n",
    "    # date: string with the date\n",
    "    # return: int with the year * 100 + month\n",
    "\n",
    "    # Check if the date is in the format YYYY-MM-DD hh:mm:ss\n",
    "    if \"-\" in date:\n",
    "        return int(date[:4]) * 100 + int(date[5:7].replace(\"-\", \"\"))\n",
    "    else: # date is in the format DD/MM/YYYY, hh:mm:ss PM\n",
    "        split = date.split(\",\")[0].split(\"/\")\n",
    "        return int(split[2]) * 100 + int(split[1])\n",
    "\n",
    "# Extract the year from the date column\n",
    "extractYearOp = (lambda df, arg: applyToCol(df, arg, extractYear))\n",
    "operateDFs(dict, extractYearOp, \"time\")\n",
    "operateDFs(challengeRows, extractYearOp, \"time\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expression column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Java library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Java libraries\n",
    "if not jpype.isJVMStarted():\n",
    "    jpype.startJVM(classpath=['../lib/org/higena/higena/1.0.0/higena-1.0.0.jar'])\n",
    "\n",
    "# Import the Java classes\n",
    "CompUtil = jpype.JClass('edu.mit.csail.sdg.parser.CompUtil')\n",
    "Reporter = jpype.JClass('edu.mit.csail.sdg.alloy4.A4Reporter')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Expr column that contains the expression written by the student to the respective predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Java classes\n",
    "ExprParser = jpype.JClass('org.higena.parser.ExprExtractor')\n",
    "def getExpr(code: str, cmd: str):\n",
    "    # Get the expression of a predicate\n",
    "    # code: string with the code\n",
    "    # cmd: predicate name\n",
    "    # return: string with the expression of the predicate\n",
    "    parser = ExprParser(code)\n",
    "    return str(parser.parse(cmd)).strip()\n",
    "\n",
    "def genExprColum(dict):\n",
    "    # Iterate datasets \n",
    "    for df in dict.values():\n",
    "        df[\"expr\"] = df.apply(lambda x: getExpr(x[\"code\"], x[\"cmd_n\"]), axis=1)\n",
    "\n",
    "genExprColum(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zKAYz8BCDmHKgNoSx</td>\n",
       "      <td>prop8</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>dvhCng5AdxC8MqjFy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202012</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8FmQ9PNWT2SXncTxX</td>\n",
       "      <td>prop10</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>5eT7wTw5kT8DwTbu2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201911</td>\n",
       "      <td>always all f:File | f in Protected implies f i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eyGu5DYCrnk58G2fJ</td>\n",
       "      <td>prop7</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>niLmMRmm94Hz6ymcD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202012</td>\n",
       "      <td>always some Protected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbr9Aq6WfBLHrvE8</td>\n",
       "      <td>prop19</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>DnAm62D7JaqDzyy5y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202011</td>\n",
       "      <td>always (all f : File | f in Protected until f ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNegade3hLiutxCru</td>\n",
       "      <td>prop11</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>cjK4u23ZAfYm8fatA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202001</td>\n",
       "      <td>File - Protected in Protected'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id   cmd_n  \\\n",
       "0  zKAYz8BCDmHKgNoSx   prop8   \n",
       "1  8FmQ9PNWT2SXncTxX  prop10   \n",
       "2  eyGu5DYCrnk58G2fJ   prop7   \n",
       "3  Akbr9Aq6WfBLHrvE8  prop19   \n",
       "4  MNegade3hLiutxCru  prop11   \n",
       "\n",
       "                                                code       derivationOf  sat  \\\n",
       "0  var sig File { var link : lone File } var sig ...  dvhCng5AdxC8MqjFy  1.0   \n",
       "1  var sig File { var link : lone File } var sig ...  5eT7wTw5kT8DwTbu2  1.0   \n",
       "2  var sig File { var link : lone File } var sig ...  niLmMRmm94Hz6ymcD  1.0   \n",
       "3  var sig File { var link : lone File } var sig ...  DnAm62D7JaqDzyy5y  1.0   \n",
       "4  var sig File { var link : lone File } var sig ...  cjK4u23ZAfYm8fatA  1.0   \n",
       "\n",
       "     time                                               expr  \n",
       "0  202012                                                     \n",
       "1  201911  always all f:File | f in Protected implies f i...  \n",
       "2  202012                              always some Protected  \n",
       "3  202011  always (all f : File | f in Protected until f ...  \n",
       "4  202001                     File - Protected in Protected'  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "dict[\"9jPK8KBWzjFmBx4Hb\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add challenge code to dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add submissions to the dataset that represent the initial state of the challenge (the empty submission) and the teacher's solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows added: 366\n"
     ]
    }
   ],
   "source": [
    "def genEmptySubmission(challengeDf): \n",
    "    # Generate an empty submission\n",
    "    # challengeDf: dataframe with one row with the challenge\n",
    "    # return: dataframe with one row with the empty submission for the challenge\n",
    "\n",
    "    challengeRow = challengeDf # Copy the dictionary\n",
    "    challengeRow[\"sat\"] = [1.0] # Empty submission is incorrect\n",
    "    challengeRow[\"expr\"] = [\"EMPTY\"] # Empty submission has an empty expression\n",
    "    challengeRow[\"derivationOf\"] = [\"\"] # Does not derive from any other challenge\n",
    "\n",
    "    return challengeRow\n",
    "\n",
    "def getSolutions(code):\n",
    "    # Get the solutions of a challenge\n",
    "    # code: string with the code\n",
    "    # return: dictionary with the solutions where the key is the predicate name and the value is the solution expression\n",
    "\n",
    "    result = {} # Initialize dictionary\n",
    "    module = CompUtil.parseEverything_fromString(Reporter(), code)\n",
    "\n",
    "    # Set keys of the dictionary: predicates to be completed by students (empty predicates)\n",
    "    for fun in module.getAllFunc():\n",
    "        if \"$$Default\" not in fun.label and fun.getBody().toString().equals(\"true\"): # Empty predicate has the body \"true\"\n",
    "            result[str(fun.label).removeprefix(\"this/\")] = \"\" \n",
    "\n",
    "    # Get the solutions\n",
    "    for fun in module.getAllFunc():\n",
    "        label = str(fun.label).removeprefix(\"this/\")\n",
    "        if label in result: # Skip if predicate in dictionary\n",
    "            continue\n",
    "\n",
    "        # Check for variations of 'oracle' in label\n",
    "        possible_keys = [label.removesuffix(suffix) for suffix in [\"o\", \"O\", \"oracle\"] if label.endswith(suffix)]\n",
    "        for key in possible_keys:\n",
    "            if key in result:\n",
    "                result[key] = getExpr(code, label)\n",
    "                break\n",
    "\n",
    "    return result\n",
    "\n",
    "def addChallengeRows(dict, challengeRows):\n",
    "    # Add the challenge rows \n",
    "    # dict: dictionary of dataframes\n",
    "    # challengeRows: dictionary of dataframes with the challenge rows\n",
    "    # return: dictionary of dataframes with the challenge rows added\n",
    "    total = 0 # Initialize total number of rows\n",
    "\n",
    "    # Iterate datasets\n",
    "    for challenge in dict.keys():\n",
    "        # Get the initial empty submission for the challenge and set its fields \n",
    "        challenge_row = genEmptySubmission(challengeRows[challenge])\n",
    "        # Get the solutions of the challenge\n",
    "        challenge_solutions = getSolutions(challenge_row[\"code\"].values[0])\n",
    "\n",
    "        # Gen the teacher solution\n",
    "        solution_row = challenge_row.copy()\n",
    "        solution_row[\"sat\"] = [0.0] # Correct\n",
    "        solution_row[\"derivationOf\"] = [challenge]\n",
    "\n",
    "        for pred, solution in challenge_solutions.items():\n",
    "            # Set up and append the challenge empty row to the dataframe\n",
    "            challenge_row[\"cmd_n\"] = [pred]\n",
    "            dict[challenge] = pd.concat([dict[challenge], challenge_row], ignore_index=True)\n",
    "\n",
    "            # Set up and append the teacher solution row to the dataframe\n",
    "            solution_row[\"expr\"] = [solution] \n",
    "            solution_row[\"cmd_n\"] = [pred]\n",
    "            solution_row[\"_id\"] = [\"sol_\" + pred]\n",
    "            dict[challenge] = pd.concat([dict[challenge], solution_row], ignore_index=True)\n",
    "            # Update total number of rows\n",
    "            total += 2\n",
    "    \n",
    "    print(\"Total number of rows added: \" + str(total))\n",
    "    return dict\n",
    "\n",
    "dict = addChallengeRows(dict, challengeRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4352</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>201910</td>\n",
       "      <td>EMPTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>prop2</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>201910</td>\n",
       "      <td>EMPTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>prop3</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>201910</td>\n",
       "      <td>EMPTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>prop4</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>201910</td>\n",
       "      <td>EMPTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>prop5</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>201910</td>\n",
       "      <td>EMPTY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id  cmd_n  \\\n",
       "4352  9jPK8KBWzjFmBx4Hb  prop1   \n",
       "4354  9jPK8KBWzjFmBx4Hb  prop2   \n",
       "4356  9jPK8KBWzjFmBx4Hb  prop3   \n",
       "4358  9jPK8KBWzjFmBx4Hb  prop4   \n",
       "4360  9jPK8KBWzjFmBx4Hb  prop5   \n",
       "\n",
       "                                                   code derivationOf  sat  \\\n",
       "4352  var sig File { var link : lone File } var sig ...               1.0   \n",
       "4354  var sig File { var link : lone File } var sig ...               1.0   \n",
       "4356  var sig File { var link : lone File } var sig ...               1.0   \n",
       "4358  var sig File { var link : lone File } var sig ...               1.0   \n",
       "4360  var sig File { var link : lone File } var sig ...               1.0   \n",
       "\n",
       "        time   expr  \n",
       "4352  201910  EMPTY  \n",
       "4354  201910  EMPTY  \n",
       "4356  201910  EMPTY  \n",
       "4358  201910  EMPTY  \n",
       "4360  201910  EMPTY  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "df = dict[\"9jPK8KBWzjFmBx4Hb\"]\n",
    "df[df[\"expr\"] == \"EMPTY\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4353</th>\n",
       "      <td>sol_prop1</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201910</td>\n",
       "      <td>no Trash+Protected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            _id  cmd_n                                               code  \\\n",
       "4353  sol_prop1  prop1  var sig File { var link : lone File } var sig ...   \n",
       "\n",
       "           derivationOf  sat    time                expr  \n",
       "4353  9jPK8KBWzjFmBx4Hb  0.0  201910  no Trash+Protected  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"_id\"] == \"sol_prop1\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Empty Submissions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove submissions with empty expression except for the inital submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total empty submissions dropped: 2205\n"
     ]
    }
   ],
   "source": [
    "def dropEmptySubmissions(dict):\n",
    "    # Drop rows that are empty submissions\n",
    "    # dict: dictionary of dataframes\n",
    "    # return: dataframe without empty submissions\n",
    "    total = 0\n",
    "    for df in dict.values():\n",
    "        # Filter rows with expr = \"\"\n",
    "        rowsToDrop = df[df[\"expr\"] == \"\"]\n",
    "        # Short circuit derivations\n",
    "        for index, row in rowsToDrop.iterrows():\n",
    "            df = shortCircuit(df, index)\n",
    "            logDrop(row[\"_id\"], \"being an empty submission.\")\n",
    "            total += 1\n",
    "    print(\"Total empty submissions dropped: \" + str(total))\n",
    "\n",
    "def fixEmpty(expr):\n",
    "    # Turn EMPTY expr to \"\"\n",
    "    # expr: string with the expression\n",
    "    # return: string with the expression fixed\n",
    "    if expr == \"EMPTY\":\n",
    "        return \"\"\n",
    "    else:\n",
    "        return expr\n",
    "\n",
    "dropEmptySubmissions(dict)\n",
    "# Turn EMPTY expr to \"\" \n",
    "fixEmptyOp = (lambda df, arg: applyToCol(df, arg, fixEmpty))\n",
    "operateDFs(dict, fixEmptyOp, \"expr\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4352</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>201910</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>prop2</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>201910</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>prop3</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>201910</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>prop4</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>201910</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360</th>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>prop5</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>201910</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    _id  cmd_n  \\\n",
       "4352  9jPK8KBWzjFmBx4Hb  prop1   \n",
       "4354  9jPK8KBWzjFmBx4Hb  prop2   \n",
       "4356  9jPK8KBWzjFmBx4Hb  prop3   \n",
       "4358  9jPK8KBWzjFmBx4Hb  prop4   \n",
       "4360  9jPK8KBWzjFmBx4Hb  prop5   \n",
       "\n",
       "                                                   code derivationOf  sat  \\\n",
       "4352  var sig File { var link : lone File } var sig ...               1.0   \n",
       "4354  var sig File { var link : lone File } var sig ...               1.0   \n",
       "4356  var sig File { var link : lone File } var sig ...               1.0   \n",
       "4358  var sig File { var link : lone File } var sig ...               1.0   \n",
       "4360  var sig File { var link : lone File } var sig ...               1.0   \n",
       "\n",
       "        time expr  \n",
       "4352  201910       \n",
       "4354  201910       \n",
       "4356  201910       \n",
       "4358  201910       \n",
       "4360  201910       "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "df = dict[\"9jPK8KBWzjFmBx4Hb\"]\n",
    "df[df[\"expr\"] == \"\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate DFs by predicate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the challenge files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseChallenges(path):\n",
    "    # Parse the challenges\n",
    "    # path: path to the challenges\n",
    "    # return: dictionary of parsed challenges with the name as key \n",
    "    challenges = {}\n",
    "    for challenge in os.listdir(path):\n",
    "        if challenge.endswith(\".als\"):\n",
    "            challenges[challenge[:-4]] = CompUtil.parseEverything_fromFile(Reporter(), None, path + challenge)\n",
    "    return challenges\n",
    "\n",
    "parsed_challenges = parseChallenges(\"datasets/challenges/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predicates to be completed by students for each challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9jPK8KBWzjFmBx4Hb': ['prop1', 'prop2', 'prop3', 'prop4', 'prop5', 'prop6', 'prop7', 'prop8', 'prop9', 'prop10', 'prop11', 'prop12', 'prop13', 'prop14', 'prop15', 'prop16', 'prop17', 'prop18', 'prop19', 'prop20'], 'aTwuoJgesSd8hXXEP': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10'], 'bNCCf9FMRZoxqobfX': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10'], 'dkZH6HJNQNLLDX6Aj': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8'], 'FwCGymHmbqcziisH5': ['prop1', 'prop2', 'prop3', 'prop4', 'prop5', 'prop6', 'prop7', 'prop8', 'prop9', 'prop10', 'prop11', 'prop12', 'prop13', 'prop14', 'prop15', 'prop16', 'prop17', 'prop18'], 'gAeD3MTGCCv8YNTaK': ['undirected', 'oriented', 'acyclic', 'complete', 'noLoops', 'weaklyConnected', 'stonglyConnected', 'transitive'], 'JC8Tij8o8GZb99gEJ': ['Inv1', 'Inv2', 'Inv3', 'Inv4'], 'JDKw8yJZF5fiP3jv3': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10', 'inv11', 'inv12', 'inv13', 'inv14', 'inv15'], 'jyS8Bmceejj9pLbTW': ['Inv1', 'Inv2', 'Inv3', 'Inv4'], 'PQAJE67kz8w5NWJuM': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10'], 'PSqwzYAfW9dFAa9im': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10', 'inv11', 'inv12', 'inv13', 'inv14', 'inv15'], 'QxGnrFQnXPGh2Lh8C': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10'], 'sDLK7uBCbgZon3znd': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10'], 'WGdhwKZnCu7aKhXq9': ['Inv1', 'Inv2', 'Inv3', 'Inv4'], 'YH3ANm7Y5Qe5dSYem': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10', 'inv11', 'inv12', 'inv13', 'inv14', 'inv15'], 'zoEADeCW2b2suJB2k': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7'], 'zRAn69AocpkmxXZnW': ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10', 'inv11', 'inv12', 'inv13', 'inv14', 'inv15']}\n"
     ]
    }
   ],
   "source": [
    "challenge_functions = {}\n",
    "for challenge, module in parsed_challenges.items():\n",
    "    challenge_functions[challenge] = [str(fun.label).removeprefix(\"this/\") for fun in module.getAllFunc() if str(fun.label) != \"this/$$Default\"]\n",
    "\n",
    "print(challenge_functions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate by predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateDerivations(df, pred, challenge):\n",
    "    # Separate derivations that belong to different predicates using short circuiting\n",
    "    # df: dataframe\n",
    "    # pred: predicate\n",
    "    # return: dataframe with independent derivations\n",
    "\n",
    "    predDf = df[df[\"cmd_n\"] == pred].copy() # Copy df filtered by predicate\n",
    "    \n",
    "    # Iterate over predDf \n",
    "    for index, row in predDf.iterrows():\n",
    "        derId = row[\"derivationOf\"] # Get the derivation of the row\n",
    "        derDf = df[df[\"_id\"] == derId] # Get the derivation row\n",
    "        \n",
    "        # Get nearest derivation with the same predicate\n",
    "        # Loop ends upon finding a row/submission with the cmd_n == pred\n",
    "        # or when the derivation is not present in the dataframe\n",
    "        # or when the derivation is the challenge row\n",
    "        while not derDf.empty and derDf.iloc[0][\"cmd_n\"] != pred and derDf.iloc[0][\"_id\"] != challenge: \n",
    "            # get previous derivation\n",
    "            derDf = df[df[\"_id\"] == derDf.iloc[0][\"derivationOf\"]] \n",
    "\n",
    "        \n",
    "        # Update the derivationOf column\n",
    "        if not derDf.empty:\n",
    "            predDf.at[index, \"derivationOf\"] = derDf.iloc[0][\"_id\"]\n",
    "\n",
    "    return predDf\n",
    "\n",
    "\n",
    "def separateDFbyPred(dict, challenge_functions):\n",
    "    # Separate the dataframes by predicate\n",
    "    # dict: dictionary of dataframes for each challenge\n",
    "    # return: dictionary of dataframes for each challenge and each predicate: dict[challenge][predicate]\n",
    "     \n",
    "    # Dictionary of dataframes for each exercise\n",
    "    allDfs = {}\n",
    "    # Iterate over the dataframes\n",
    "    for challenge, df in dict.items():\n",
    "        allDfs[challenge] = {} # init the challenge dictionary\n",
    "        # Iterate over the exercises\n",
    "        for pred in challenge_functions[challenge]:\n",
    "            # Separate derivations that belong to different predicates using short circuiting \n",
    "            allDfs[challenge][pred] = separateDerivations(df, pred, challenge).copy()\n",
    "            \n",
    "    return allDfs\n",
    "\n",
    "allDfs = separateDFbyPred(dict, challenge_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9jPK8KBWzjFmBx4Hb ['prop1', 'prop2', 'prop3', 'prop4', 'prop5', 'prop6', 'prop7', 'prop8', 'prop9', 'prop10', 'prop11', 'prop12', 'prop13', 'prop14', 'prop15', 'prop16', 'prop17', 'prop18', 'prop19', 'prop20']\n",
      "aTwuoJgesSd8hXXEP ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10']\n",
      "bNCCf9FMRZoxqobfX ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10']\n",
      "dkZH6HJNQNLLDX6Aj ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8']\n",
      "FwCGymHmbqcziisH5 ['prop1', 'prop2', 'prop3', 'prop4', 'prop5', 'prop6', 'prop7', 'prop8', 'prop9', 'prop10', 'prop11', 'prop12', 'prop13', 'prop14', 'prop15', 'prop16', 'prop17', 'prop18']\n",
      "gAeD3MTGCCv8YNTaK ['undirected', 'oriented', 'acyclic', 'complete', 'noLoops', 'weaklyConnected', 'stonglyConnected', 'transitive']\n",
      "JC8Tij8o8GZb99gEJ ['Inv1', 'Inv2', 'Inv3', 'Inv4']\n",
      "JDKw8yJZF5fiP3jv3 ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10', 'inv11', 'inv12', 'inv13', 'inv14', 'inv15']\n",
      "jyS8Bmceejj9pLbTW ['Inv1', 'Inv2', 'Inv3', 'Inv4']\n",
      "PQAJE67kz8w5NWJuM ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10']\n",
      "PSqwzYAfW9dFAa9im ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10', 'inv11', 'inv12', 'inv13', 'inv14', 'inv15']\n",
      "QxGnrFQnXPGh2Lh8C ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10']\n",
      "sDLK7uBCbgZon3znd ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10']\n",
      "WGdhwKZnCu7aKhXq9 ['Inv1', 'Inv2', 'Inv3', 'Inv4']\n",
      "YH3ANm7Y5Qe5dSYem ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10', 'inv11', 'inv12', 'inv13', 'inv14', 'inv15']\n",
      "zoEADeCW2b2suJB2k ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7']\n",
      "zRAn69AocpkmxXZnW ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10', 'inv11', 'inv12', 'inv13', 'inv14', 'inv15']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>BTJstCSFzkYQBsQx6</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>iYRoFbhfsZX6GZeZw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202011</td>\n",
       "      <td>no Trash and no Protected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>qCP5Z52W7HPyPhM66</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>9YjrCv4G59r5iMJ9Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202011</td>\n",
       "      <td>before no Trash + Protected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>g3pdisnaMXvFwwdJH</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>EMz6E2zDEyB6JkAdX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202011</td>\n",
       "      <td>no Trash and no (Protected )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>ZA4XCBD3yxP9xNLRK</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202011</td>\n",
       "      <td>historically (no Trash and no Protected)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>vqNQs258RTS8dxWop</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202101</td>\n",
       "      <td>historically no (Trash + Protected)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id  cmd_n  \\\n",
       "134  BTJstCSFzkYQBsQx6  prop1   \n",
       "146  qCP5Z52W7HPyPhM66  prop1   \n",
       "210  g3pdisnaMXvFwwdJH  prop1   \n",
       "241  ZA4XCBD3yxP9xNLRK  prop1   \n",
       "254  vqNQs258RTS8dxWop  prop1   \n",
       "\n",
       "                                                  code       derivationOf  \\\n",
       "134  var sig File { var link : lone File } var sig ...  iYRoFbhfsZX6GZeZw   \n",
       "146  var sig File { var link : lone File } var sig ...  9YjrCv4G59r5iMJ9Y   \n",
       "210  var sig File { var link : lone File } var sig ...  EMz6E2zDEyB6JkAdX   \n",
       "241  var sig File { var link : lone File } var sig ...  9jPK8KBWzjFmBx4Hb   \n",
       "254  var sig File { var link : lone File } var sig ...  9jPK8KBWzjFmBx4Hb   \n",
       "\n",
       "     sat    time                                      expr  \n",
       "134  0.0  202011                 no Trash and no Protected  \n",
       "146  1.0  202011               before no Trash + Protected  \n",
       "210  0.0  202011              no Trash and no (Protected )  \n",
       "241  0.0  202011  historically (no Trash and no Protected)  \n",
       "254  0.0  202101       historically no (Trash + Protected)  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "for challenge, preds in allDfs.items():\n",
    "    print(challenge, list(preds.keys()))\n",
    "\n",
    "allDfs[\"9jPK8KBWzjFmBx4Hb\"][\"prop1\"].head() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add AST column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Java classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTParser = jpype.JClass('org.higena.parser.A4FParser')\n",
    "SyntaxError = jpype.JClass('edu.mit.csail.sdg.alloy4.ErrorSyntax')\n",
    "TypeError = jpype.JClass('edu.mit.csail.sdg.alloy4.ErrorType')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3 new dataframes:\n",
    "- One with ASTs without any canonicalization\n",
    "- One with variable anonymization\n",
    "- One with commutative operation sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyDfs(allDfs):\n",
    "    # Copy the dataframes\n",
    "    # allDfs: dictionary of dataframes\n",
    "    # return: dictionary of dataframes\n",
    "    copy = {}\n",
    "    for challenge, preds in allDfs.items():\n",
    "        copy[challenge] = {}\n",
    "        for pred, df in preds.items():\n",
    "            copy[challenge][pred] = df.copy()\n",
    "    return copy\n",
    "\n",
    "no_canon = copyDfs(allDfs)\n",
    "only_anon = copyDfs(allDfs)\n",
    "only_sort = copyDfs(allDfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logError(id, challenge, error, expr):\n",
    "    # Log an error\n",
    "    # id: id of the submission\n",
    "    # challenge: id of the challenge\n",
    "    # error: error message\n",
    "    # expr: expression that failed\n",
    "    file = open(log_file_ast, \"a\")\n",
    "    file.write(\"\\n- Submission: \" + id + \" Challenge: \" + challenge + \" Expr: \" + expr + \"\\n\\t\" + str(error) + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "def parseExpr(id, expr, fullCode, challenge, parsedChallenge):\n",
    "    # Parse an expression\n",
    "    # expr: string with the expression\n",
    "    # fullCode: string with the full code\n",
    "    # challenge: id of the challenge\n",
    "    # parsedChallenge: parsed challenge module\n",
    "    # return: parsed expression\n",
    "\n",
    "    # Handle empty submissions (challenge code)\n",
    "    if expr == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    parsed = None\n",
    "    try:\n",
    "        parsed = str(ASTParser.parse(expr, parsedChallenge).toTreeString())\n",
    "    except Exception as e:\n",
    "        # Try to parse the full code\n",
    "        try:\n",
    "            parsed = str(ASTParser.parse(expr, fullCode).toTreeString())\n",
    "        except Exception as e:\n",
    "            logError(id, challenge, e, expr)\n",
    "\n",
    "    return parsed\n",
    "\n",
    "def addASTsColumns(allDfs, parsed_challenges):\n",
    "    # Add the ASTs columns\n",
    "    # allDfs: dictionary of dataframes for each challenge and each predicate\n",
    "    # parsed_challenges: dictionary of parsed challenges\n",
    "    # return: dictionary of dataframes for each challenge and each predicate with the ASTs columns\n",
    "\n",
    "    # Iterate over the challenges\n",
    "    for challenge, cmdDfs in allDfs.items():\n",
    "        # Get parsed challenge\n",
    "\n",
    "        # Iterate over the submission for each command\n",
    "        for cmd, df in cmdDfs.items():\n",
    "            df[\"ast\"] = df[[\"_id\", \"expr\", \"code\", \"cmd_n\"]].apply(lambda x: parseExpr(x[\"_id\"], x[\"expr\"], x[\"code\"], challenge, parsed_challenges[challenge]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASTs without canonicalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the ASTs columns\n",
    "ASTParser.ANONYMIZE = True\n",
    "ASTParser.SORT_COMMUTATIVE = True\n",
    "addASTsColumns(allDfs, parsed_challenges)\n",
    "\n",
    "ASTParser.ANONYMIZE = False\n",
    "ASTParser.SORT_COMMUTATIVE = False\n",
    "addASTsColumns(no_canon, parsed_challenges)\n",
    "\n",
    "ASTParser.ANONYMIZE = True\n",
    "ASTParser.SORT_COMMUTATIVE = False\n",
    "addASTsColumns(only_anon, parsed_challenges)\n",
    "\n",
    "ASTParser.ANONYMIZE = False\n",
    "ASTParser.SORT_COMMUTATIVE = True\n",
    "addASTsColumns(only_sort, parsed_challenges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>expr</th>\n",
       "      <th>ast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>BTJstCSFzkYQBsQx6</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File { var link : lone File } var sig ...</td>\n",
       "      <td>iYRoFbhfsZX6GZeZw</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202011</td>\n",
       "      <td>no Trash and no Protected</td>\n",
       "      <td>{AND{no{sig/Trash}}{no{sig/Protected}}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id  cmd_n  \\\n",
       "134  BTJstCSFzkYQBsQx6  prop1   \n",
       "\n",
       "                                                  code       derivationOf  \\\n",
       "134  var sig File { var link : lone File } var sig ...  iYRoFbhfsZX6GZeZw   \n",
       "\n",
       "     sat    time                       expr  \\\n",
       "134  0.0  202011  no Trash and no Protected   \n",
       "\n",
       "                                         ast  \n",
       "134  {AND{no{sig/Trash}}{no{sig/Protected}}}  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "allDfs[\"9jPK8KBWzjFmBx4Hb\"][\"prop1\"].head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean submissions without ASTs. (With syntax errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 1\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Removed submissions with no ASTs.\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 1\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Removed submissions with no ASTs.\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 1\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Removed submissions with no ASTs.\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 1\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Total number of rows dropped: 0\n",
      "Removed submissions with no ASTs.\n"
     ]
    }
   ],
   "source": [
    "def removeEmptyASTs(allDfs):\n",
    "    # Remove the empty ASTs\n",
    "    # allDfs: dictionary of dataframes for each challenge and each predicate\n",
    "    # return: dictionary of dataframes for each challenge and each predicate\n",
    "\n",
    "    # Iterate over the challenges\n",
    "    for cmdDfs in allDfs.values():\n",
    "       cmdDfs = dropNulls(cmdDfs, \"ast\") \n",
    "           \n",
    "    print(\"Removed submissions with no ASTs.\")\n",
    "    return allDfs\n",
    "\n",
    "allDfs = removeEmptyASTs(allDfs)\n",
    "no_canon = removeEmptyASTs(no_canon)\n",
    "only_anon = removeEmptyASTs(only_anon)\n",
    "only_sort = removeEmptyASTs(only_sort)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split test and train data. Train data stands from 2019 to 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202011    68\n",
       "202012    28\n",
       "201910    27\n",
       "202101    11\n",
       "202001     9\n",
       "201911     6\n",
       "202202     4\n",
       "Name: time, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the dictionaries \n",
    "trainDfs = {}\n",
    "testDfs = {}\n",
    "\n",
    "# Iterate over the challenges\n",
    "for challenge, cmdDfs in allDfs.items(): \n",
    "    trainDfs[challenge] = {}\n",
    "    testDfs[challenge] = {}\n",
    "    # Iterate over the predicates\n",
    "    for cmd, df in cmdDfs.items():\n",
    "        trainDfs[challenge][cmd] = df[(df[\"time\"] < 202306)].copy()\n",
    "        testDfs[challenge][cmd] = df[(df[\"time\"] >= 202306) & (df[\"sat\"] == 1.0)].copy()\n",
    "\n",
    "# Check\n",
    "trainDfs[\"9jPK8KBWzjFmBx4Hb\"][\"prop1\"][\"time\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove test duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for challenge, cmdDfs in testDfs.items():\n",
    "    for cmd, df in cmdDfs.items():\n",
    "        # Remove duplicates\n",
    "        df.drop_duplicates(subset=[\"expr\"], inplace=True)\n",
    "        df.drop_duplicates(subset=[\"ast\"], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportData(allDfs, path, fileType=\"csv\"):\n",
    "    # Export the dataframes to csv files\n",
    "    # allDfs: dictionary of dataframes for each challenge and each predicate \n",
    "    # path: path to export the dataframes\n",
    "\n",
    "    # Iterate over the challenges\n",
    "    for challenge, cmdDfs in allDfs.items():\n",
    "        # Create folder if it does not exist\n",
    "        folder = path + challenge + \"/\"\n",
    "        if os.path.exists(folder):\n",
    "            # Delete all files\n",
    "            fileList = [f for f in os.listdir(folder)]\n",
    "            for f in fileList:\n",
    "                os.remove(os.path.join(folder, f))\n",
    "        else:\n",
    "            # Create folder\n",
    "            os.makedirs(folder)\n",
    "\n",
    "        # Iterate over the submission for each commantime/timed\n",
    "        for cmd, df in cmdDfs.items():\n",
    "            # Skip empty dataframes\n",
    "            if df.empty:\n",
    "                continue\n",
    "            # Export dataframe to csv\n",
    "            if fileType == \"csv\":\n",
    "                file = folder + cmd + \".csv\"\n",
    "                df.to_csv(file, index=False)\n",
    "            elif fileType == \"json\":\n",
    "                file = folder + cmd + \".json\"\n",
    "                df.to_json(file, orient='records', lines=True)\n",
    "            else: \n",
    "                print(\"File type not supported\")\n",
    "                return\n",
    "\n",
    "# Export the dataframes to db\n",
    "output_dir = \"./datasets/prepared/\"\n",
    "exportData(trainDfs, output_dir + \"train/\")\n",
    "exportData(testDfs, output_dir + \"test/\", \"json\")\n",
    "exportData(allDfs, output_dir + \"all/\")\n",
    "exportData(no_canon, output_dir + \"no_canon/\")\n",
    "exportData(only_anon, output_dir + \"only_anon/\")\n",
    "exportData(only_sort, output_dir + \"only_sort/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
