{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alloy4Fun Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os \n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def importDataFromDir(dir):\n",
    "    # Import all the data from a directory\n",
    "    # dir: directory with the data\n",
    "    # return: a dictionary of dataframes\n",
    "    dict = {}\n",
    "\n",
    "    for file in os.listdir(dir):\n",
    "        if file.endswith('.json'):\n",
    "            df = pd.read_json(f'{dir}/' + file, lines=True)\n",
    "            dict[file.removesuffix(\".json\")] = df\n",
    "            print(f\"Imported {file}.\")\n",
    "\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 9jPK8KBWzjFmBx4Hb.json.\n",
      "Imported FwCGymHmbqcziisH5.json.\n",
      "Imported gAeD3MTGCCv8YNTaK.json.\n",
      "Imported JC8Tij8o8GZb99gEJ.json.\n",
      "Imported jyS8Bmceejj9pLbTW.json.\n",
      "Imported PQAJE67kz8w5NWJuM.json.\n",
      "Imported sDLK7uBCbgZon3znd.json.\n",
      "Imported WGdhwKZnCu7aKhXq9.json.\n",
      "Imported YH3ANm7Y5Qe5dSYem.json.\n",
      "Imported zoEADeCW2b2suJB2k.json.\n",
      "Imported zRAn69AocpkmxXZnW.json.\n"
     ]
    }
   ],
   "source": [
    "# Import files from the data directory\n",
    "dict = importDataFromDir('data/submissions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_c</th>\n",
       "      <th>cmd_i</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>original</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>msg</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zKAYz8BCDmHKgNoSx</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>prop8Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>dvhCng5AdxC8MqjFy</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-13 23:28:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8FmQ9PNWT2SXncTxX</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>prop10Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>5eT7wTw5kT8DwTbu2</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-11-11 21:54:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eyGu5DYCrnk58G2fJ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>prop7Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>niLmMRmm94Hz6ymcD</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-12-1 11:55:11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbr9Aq6WfBLHrvE8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>prop19Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>DnAm62D7JaqDzyy5y</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-11-26 10:33:29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNegade3hLiutxCru</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>prop11Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>cjK4u23ZAfYm8fatA</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-1-19 17:06:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id  cmd_c  cmd_i     cmd_n  \\\n",
       "0  zKAYz8BCDmHKgNoSx    1.0    7.0   prop8Ok   \n",
       "1  8FmQ9PNWT2SXncTxX    1.0    9.0  prop10Ok   \n",
       "2  eyGu5DYCrnk58G2fJ    1.0    6.0   prop7Ok   \n",
       "3  Akbr9Aq6WfBLHrvE8    1.0   18.0  prop19Ok   \n",
       "4  MNegade3hLiutxCru    1.0   10.0  prop11Ok   \n",
       "\n",
       "                                                code       derivationOf  \\\n",
       "0  /**\\n * Linear temporal logic revision exercis...  dvhCng5AdxC8MqjFy   \n",
       "1  /**\\n * Linear temporal logic revision exercis...  5eT7wTw5kT8DwTbu2   \n",
       "2  /**\\n * Linear temporal logic revision exercis...  niLmMRmm94Hz6ymcD   \n",
       "3  /**\\n * Linear temporal logic revision exercis...  DnAm62D7JaqDzyy5y   \n",
       "4  /**\\n * Linear temporal logic revision exercis...  cjK4u23ZAfYm8fatA   \n",
       "\n",
       "            original  sat                 time  msg theme  \n",
       "0  9jPK8KBWzjFmBx4Hb  1.0  2020-12-13 23:28:11  NaN   NaN  \n",
       "1  9jPK8KBWzjFmBx4Hb  1.0  2019-11-11 21:54:33  NaN   NaN  \n",
       "2  9jPK8KBWzjFmBx4Hb  1.0   2020-12-1 11:55:11  NaN   NaN  \n",
       "3  9jPK8KBWzjFmBx4Hb  1.0  2020-11-26 10:33:29  NaN   NaN  \n",
       "4  9jPK8KBWzjFmBx4Hb  1.0   2020-1-19 17:06:22  NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = dict[\"9jPK8KBWzjFmBx4Hb\"]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                0\n",
       "cmd_c            915\n",
       "cmd_i             35\n",
       "cmd_n            915\n",
       "code               0\n",
       "derivationOf       0\n",
       "original           0\n",
       "sat               35\n",
       "time               0\n",
       "msg             4353\n",
       "theme           5218\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features meaning:\n",
    "- _id: the id of the interaction\n",
    "- time: the timestamp of its creation\n",
    "- derivationOf: the parent entry\n",
    "- original: the first ancestor with secrets (always the same within an exercise)\n",
    "- code: the complete code of the model (excluding the secrets defined in the original entry) (with student comments removed)\n",
    "- sat: whether the command was satisfiable (counter-example found for checks), or -1 when error thrown [only for executions]\n",
    "- cmd_i: the index of the executed command [only for executions]\n",
    "- cmd_n: the name of the executed command [only for successful executions, i.e. no error thrown]\n",
    "- cmd_c: whether the command was a check [only for successful executions, i.e. no error thrown]\n",
    "- msg: the error or warning message [only for successful executions with warnings or when error thrown]\n",
    "- theme: the visualisation theme [only for sharing entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cmd_i null values\n",
    "\n",
    "cmd_i is null for non-executions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_c</th>\n",
       "      <th>cmd_i</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>original</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>msg</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>P3gFuEkajduWTyFeo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>6YmxWkc8PtXEqdafi</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-31 11:47:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>K2ejbWj7HT3mSFdym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>4zDygwoYWF7AAqHv8</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-1-3 13:48:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>MdZs9uee25QgFwvi7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>kb8KrpANCxg9XXcLs</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-31 11:48:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>fWKpSLkdPZPxkSoJe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>8KGv5F6b8ySPofNdJ</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-31 11:52:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>ggNDTsgGfpet9HqvY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>NdNtvRAx8r85Fivh8</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-24 01:32:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'currentFramePosition': {}, 'currentlyProject...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id  cmd_c  cmd_i cmd_n  \\\n",
       "32   P3gFuEkajduWTyFeo    NaN    NaN   NaN   \n",
       "159  K2ejbWj7HT3mSFdym    NaN    NaN   NaN   \n",
       "301  MdZs9uee25QgFwvi7    NaN    NaN   NaN   \n",
       "337  fWKpSLkdPZPxkSoJe    NaN    NaN   NaN   \n",
       "353  ggNDTsgGfpet9HqvY    NaN    NaN   NaN   \n",
       "\n",
       "                                                  code       derivationOf  \\\n",
       "32   /**\\n * Linear temporal logic revision exercis...  6YmxWkc8PtXEqdafi   \n",
       "159  /**\\n * Linear temporal logic revision exercis...  4zDygwoYWF7AAqHv8   \n",
       "301  /**\\n * Linear temporal logic revision exercis...  kb8KrpANCxg9XXcLs   \n",
       "337  /**\\n * Linear temporal logic revision exercis...  8KGv5F6b8ySPofNdJ   \n",
       "353  /**\\n * Linear temporal logic revision exercis...  NdNtvRAx8r85Fivh8   \n",
       "\n",
       "              original  sat                 time  msg  \\\n",
       "32   9jPK8KBWzjFmBx4Hb  NaN  2019-10-31 11:47:23  NaN   \n",
       "159  9jPK8KBWzjFmBx4Hb  NaN    2020-1-3 13:48:36  NaN   \n",
       "301  9jPK8KBWzjFmBx4Hb  NaN  2019-10-31 11:48:12  NaN   \n",
       "337  9jPK8KBWzjFmBx4Hb  NaN  2019-10-31 11:52:15  NaN   \n",
       "353  9jPK8KBWzjFmBx4Hb  NaN  2020-11-24 01:32:37  NaN   \n",
       "\n",
       "                                                 theme  \n",
       "32   {'currentFramePosition': {}, 'currentlyProject...  \n",
       "159  {'currentFramePosition': {}, 'currentlyProject...  \n",
       "301  {'currentFramePosition': {}, 'currentlyProject...  \n",
       "337  {'currentFramePosition': {}, 'currentlyProject...  \n",
       "353  {'currentFramePosition': {}, 'currentlyProject...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows with cmd_i = null\n",
    "nullDF = df1[df1[\"cmd_i\"].isnull()]\n",
    "nullDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with cmd_i null:  35\n",
      "Rows with sat null:  35\n",
      "Rows with cmd_c null :  35\n",
      "Rows with cmd_n null :  35\n",
      "Rows with theme null :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows with cmd_i null: \", len(nullDF))\n",
    "print(\"Rows with sat null: \", len(nullDF[nullDF[\"sat\"].isnull()]))\n",
    "print(\"Rows with cmd_c null : \", len(nullDF[nullDF[\"cmd_c\"].isnull()]))\n",
    "print(\"Rows with cmd_n null : \", len(nullDF[nullDF[\"cmd_n\"].isnull()]))\n",
    "print(\"Rows with theme null : \", len(nullDF[nullDF[\"theme\"].isnull()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever cmd_i is null it means that there was no execution. It is the sharing of a model. This cases might be irrelevant to the problem so they can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_c</th>\n",
       "      <th>cmd_i</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>original</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>msg</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_id, cmd_c, cmd_i, cmd_n, code, derivationOf, original, sat, time, msg, theme]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shortCircuit(df, row, index):\n",
    "    # Short circuit the derivation of a row.\n",
    "    # If A derives B and B derives C, then A derives C and B is removed.\n",
    "    # df: dataframe\n",
    "    # row: row to short circuit\n",
    "    # return: dataframe with the row short circuited\n",
    "\n",
    "    # Get row information\n",
    "    id = row[\"_id\"]\n",
    "    derivation = row[\"derivationOf\"]\n",
    "\n",
    "    # Remove row\n",
    "    df.drop(index, inplace=True)\n",
    "\n",
    "    # Get derivations of row\n",
    "    derivationSet = df[df[\"derivationOf\"] == id] \n",
    "    # Short circuit derivations\n",
    "    df.loc[df[\"derivationOf\"] == id, \"derivationOf\"] = derivation\n",
    "\n",
    "    return df\n",
    "\n",
    "def dropNulls(dict, col):\n",
    "    # Remove rows with col null\n",
    "    # dict: dictionary of dataframes\n",
    "    # return: dataframe with rows with col null removed\n",
    "\n",
    "    for df in dict.values():\n",
    "        # Filter rows with col= null\n",
    "        nullDF = df[df[col].isnull()]\n",
    "        # Short circuit derivations\n",
    "        for index, row in nullDF.iterrows():\n",
    "            df = shortCircuit(df, row, index)\n",
    "\n",
    "    return dict\n",
    "\n",
    "\n",
    "# Drop rows with cmd_i null\n",
    "dict = dropNulls(dict, \"cmd_i\")\n",
    "# Check results\n",
    "df1 = dict[\"9jPK8KBWzjFmBx4Hb\"]\n",
    "nullDF = df1[df1[\"cmd_i\"].isnull()]\n",
    "nullDF.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cmd_c and cmd_n null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_c</th>\n",
       "      <th>cmd_i</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>original</th>\n",
       "      <th>sat</th>\n",
       "      <th>time</th>\n",
       "      <th>msg</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nuWnon2d7N7N7ZFvw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>ZjxPhwuLGd52cZyox</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2020-11-23 23:09:43</td>\n",
       "      <td>There are 1 possible tokens that can appear he...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sxuHvWgfPeRh9QYYy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>RBovdMdE7s7k2Z3xY</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2020-12-1 21:46:47</td>\n",
       "      <td>There are 37 possible tokens that can appear h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xPeTe3FdpxzspZTta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>t45BxKKpdXbYN4Aun</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2020-11-26 10:17:06</td>\n",
       "      <td>There are 1 possible tokens that can appear he...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GQbQyxLarysc73gH7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>2js6dSN2dk4HhJmbF</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2020-12-1 11:39:04</td>\n",
       "      <td>There are 37 possible tokens that can appear h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CCt6wniT5St2hKKFr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-10-31 10:48:50</td>\n",
       "      <td>There are 29 possible tokens that can appear h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  _id  cmd_c  cmd_i cmd_n  \\\n",
       "13  nuWnon2d7N7N7ZFvw    NaN    7.0   NaN   \n",
       "14  sxuHvWgfPeRh9QYYy    NaN    7.0   NaN   \n",
       "16  xPeTe3FdpxzspZTta    NaN    7.0   NaN   \n",
       "20  GQbQyxLarysc73gH7    NaN    3.0   NaN   \n",
       "25  CCt6wniT5St2hKKFr    NaN    0.0   NaN   \n",
       "\n",
       "                                                 code       derivationOf  \\\n",
       "13  /**\\n * Linear temporal logic revision exercis...  ZjxPhwuLGd52cZyox   \n",
       "14  /**\\n * Linear temporal logic revision exercis...  RBovdMdE7s7k2Z3xY   \n",
       "16  /**\\n * Linear temporal logic revision exercis...  t45BxKKpdXbYN4Aun   \n",
       "20  /**\\n * Linear temporal logic revision exercis...  2js6dSN2dk4HhJmbF   \n",
       "25  /**\\n * Linear temporal logic revision exercis...  9jPK8KBWzjFmBx4Hb   \n",
       "\n",
       "             original  sat                 time  \\\n",
       "13  9jPK8KBWzjFmBx4Hb -1.0  2020-11-23 23:09:43   \n",
       "14  9jPK8KBWzjFmBx4Hb -1.0   2020-12-1 21:46:47   \n",
       "16  9jPK8KBWzjFmBx4Hb -1.0  2020-11-26 10:17:06   \n",
       "20  9jPK8KBWzjFmBx4Hb -1.0   2020-12-1 11:39:04   \n",
       "25  9jPK8KBWzjFmBx4Hb -1.0  2019-10-31 10:48:50   \n",
       "\n",
       "                                                  msg theme  \n",
       "13  There are 1 possible tokens that can appear he...   NaN  \n",
       "14  There are 37 possible tokens that can appear h...   NaN  \n",
       "16  There are 1 possible tokens that can appear he...   NaN  \n",
       "20  There are 37 possible tokens that can appear h...   NaN  \n",
       "25  There are 29 possible tokens that can appear h...   NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows with cmd_c = null\n",
    "nullDF = df1[df1[\"cmd_c\"].isnull()]\n",
    "nullDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with cmd_c null:  880\n",
      "Rows with cmd_n null:  880\n",
      "Rows with msg null:  0\n",
      "Rows with negative sat:  880\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows with cmd_c null: \", len(nullDF))\n",
    "print(\"Rows with cmd_n null: \", len(nullDF[nullDF[\"cmd_n\"].isnull()]))\n",
    "print(\"Rows with msg null: \", len(nullDF[nullDF[\"msg\"].isnull()]))\n",
    "print(\"Rows with negative sat: \", len(nullDF[nullDF[\"sat\"] == -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever cmd_c is null, cmd_n is also null. These values are null for cases where a syntactic error is thrown and a msg appears.\n",
    "The code in these case is not parseable. We can drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id                0\n",
       "cmd_c              0\n",
       "cmd_i              0\n",
       "cmd_n              0\n",
       "code               0\n",
       "derivationOf       0\n",
       "original           0\n",
       "sat                0\n",
       "time               0\n",
       "msg             4318\n",
       "theme           4338\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with cmd_c null\n",
    "dict = dropNulls(dict, \"cmd_c\")\n",
    "# Check results\n",
    "df1 = dict[\"9jPK8KBWzjFmBx4Hb\"]\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with mgs and theme null values is not important in these context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove extra features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cmd_c feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 21234, 0.0: 23})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def countValues(dict, col):\n",
    "    # Count the values in a column\n",
    "    # df: dataframe\n",
    "    # col: column to count\n",
    "    # return: dataframe with the counts\n",
    "    totalCount = collections.Counter()\n",
    "\n",
    "    for df in dict.values():\n",
    "        count = df[col].value_counts().to_dict()\n",
    "        totalCount.update(count)        \n",
    "\n",
    "    return totalCount\n",
    "\n",
    "# Count the different values in the cmd_c column across all the dataframes\n",
    "counter = countValues(dict, 'cmd_c')\n",
    "print(counter)\n",
    "\n",
    "plt.barh([str(k) for k in counter.keys()], counter.values())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of 0 values for the column cmd_c is irrelevant (when the executed command is not a check). For that reason, entries with these values should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1.0: 21234})\n"
     ]
    }
   ],
   "source": [
    "def dropNonChecks(dict):\n",
    "    # Drop the rows that are not checks\n",
    "    # dict: dictionary of dataframes\n",
    "    # return: dataframe with the rows that are not checks removed\n",
    "\n",
    "    for df in dict.values():\n",
    "        # Filter rows with cmd_c != 0\n",
    "        dfToDrop = df[df[\"cmd_c\"] == 0]\n",
    "        # Short circuit derivations\n",
    "        for index, row in dfToDrop.iterrows():\n",
    "            df = shortCircuit(df, row, index)\n",
    "\n",
    "    return dict\n",
    "\n",
    "# Remove the rows with the value 0 in the cmd_c column\n",
    "dropNonChecks(dict)\n",
    "\n",
    "# Count the different values in the cmd_c column\n",
    "print(countValues(dict, 'cmd_c'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9jPK8KBWzjFmBx4Hb': 4338}\n",
      "{'FwCGymHmbqcziisH5': 972}\n",
      "{'gAeD3MTGCCv8YNTaK': 1764}\n",
      "{'JC8Tij8o8GZb99gEJ': 665}\n",
      "{'jyS8Bmceejj9pLbTW': 459}\n",
      "{'PQAJE67kz8w5NWJuM': 1934}\n",
      "{'sDLK7uBCbgZon3znd': 2216}\n",
      "{'WGdhwKZnCu7aKhXq9': 283}\n",
      "{'YH3ANm7Y5Qe5dSYem': 3478}\n",
      "{'zoEADeCW2b2suJB2k': 1633}\n",
      "{'zRAn69AocpkmxXZnW': 3492}\n"
     ]
    }
   ],
   "source": [
    "def operateDFs(dict, op, arg):\n",
    "    # Operate on each dataframe in a dictionary\n",
    "    # dict: dictionary of dataframes\n",
    "    # op: operation to perform\n",
    "    # arg: argument to pass to the operation\n",
    "    for df in dict.values():\n",
    "        op(df, arg)\n",
    "\n",
    "# Count the different values for the original column for each dataframe\n",
    "countValuesOp = (lambda df, arg: print(df[arg].value_counts().to_dict()))\n",
    "operateDFs(dict, countValuesOp, 'original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every dataframe has the same value for the original column. This column is irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will drop the irrelevant columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zKAYz8BCDmHKgNoSx</td>\n",
       "      <td>prop8Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>dvhCng5AdxC8MqjFy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8FmQ9PNWT2SXncTxX</td>\n",
       "      <td>prop10Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>5eT7wTw5kT8DwTbu2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eyGu5DYCrnk58G2fJ</td>\n",
       "      <td>prop7Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>niLmMRmm94Hz6ymcD</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbr9Aq6WfBLHrvE8</td>\n",
       "      <td>prop19Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>DnAm62D7JaqDzyy5y</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNegade3hLiutxCru</td>\n",
       "      <td>prop11Ok</td>\n",
       "      <td>/**\\n * Linear temporal logic revision exercis...</td>\n",
       "      <td>cjK4u23ZAfYm8fatA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id     cmd_n  \\\n",
       "0  zKAYz8BCDmHKgNoSx   prop8Ok   \n",
       "1  8FmQ9PNWT2SXncTxX  prop10Ok   \n",
       "2  eyGu5DYCrnk58G2fJ   prop7Ok   \n",
       "3  Akbr9Aq6WfBLHrvE8  prop19Ok   \n",
       "4  MNegade3hLiutxCru  prop11Ok   \n",
       "\n",
       "                                                code       derivationOf  sat  \n",
       "0  /**\\n * Linear temporal logic revision exercis...  dvhCng5AdxC8MqjFy  1.0  \n",
       "1  /**\\n * Linear temporal logic revision exercis...  5eT7wTw5kT8DwTbu2  1.0  \n",
       "2  /**\\n * Linear temporal logic revision exercis...  niLmMRmm94Hz6ymcD  1.0  \n",
       "3  /**\\n * Linear temporal logic revision exercis...  DnAm62D7JaqDzyy5y  1.0  \n",
       "4  /**\\n * Linear temporal logic revision exercis...  cjK4u23ZAfYm8fatA  1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns that are not needed\n",
    "dropColOp = (lambda df, arg: df.drop(columns=arg, axis=1, inplace=True))\n",
    "operateDFs(dict, dropColOp, [\"cmd_c\", \"cmd_i\", \"original\", \"time\", \"msg\", \"theme\"])\n",
    "\n",
    "dict[\"9jPK8KBWzjFmBx4Hb\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code cleaning\n",
    "\n",
    "The code in this dataset comes with comments that can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zKAYz8BCDmHKgNoSx</td>\n",
       "      <td>prop8Ok</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>dvhCng5AdxC8MqjFy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8FmQ9PNWT2SXncTxX</td>\n",
       "      <td>prop10Ok</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>5eT7wTw5kT8DwTbu2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eyGu5DYCrnk58G2fJ</td>\n",
       "      <td>prop7Ok</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>niLmMRmm94Hz6ymcD</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbr9Aq6WfBLHrvE8</td>\n",
       "      <td>prop19Ok</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>DnAm62D7JaqDzyy5y</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNegade3hLiutxCru</td>\n",
       "      <td>prop11Ok</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>cjK4u23ZAfYm8fatA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id     cmd_n  \\\n",
       "0  zKAYz8BCDmHKgNoSx   prop8Ok   \n",
       "1  8FmQ9PNWT2SXncTxX  prop10Ok   \n",
       "2  eyGu5DYCrnk58G2fJ   prop7Ok   \n",
       "3  Akbr9Aq6WfBLHrvE8  prop19Ok   \n",
       "4  MNegade3hLiutxCru  prop11Ok   \n",
       "\n",
       "                                                code       derivationOf  sat  \n",
       "0  var sig File {var link : lone File}var sig Tra...  dvhCng5AdxC8MqjFy  1.0  \n",
       "1  var sig File {var link : lone File}var sig Tra...  5eT7wTw5kT8DwTbu2  1.0  \n",
       "2  var sig File {var link : lone File}var sig Tra...  niLmMRmm94Hz6ymcD  1.0  \n",
       "3  var sig File {var link : lone File}var sig Tra...  DnAm62D7JaqDzyy5y  1.0  \n",
       "4  var sig File {var link : lone File}var sig Tra...  cjK4u23ZAfYm8fatA  1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re # regular expressions\n",
    "\n",
    "def cleanCode(code):\n",
    "    # Remove comments and empty lines\n",
    "    # code: string with the code\n",
    "    # return: string with the code without comments and empty lines\n",
    "    code = re.sub(r\"(/\\*(.|\\n)*?\\*/)|(//.*)\", \"\", code) # remove comments\n",
    "    code = re.sub(r\"\\n\\n(?=\\n)\", \"\", code) # remove empty lines\n",
    "    \n",
    "    return code.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "\n",
    "def applyToCol(df, col, op):\n",
    "    # Apply an operation to a column\n",
    "    # df: dataframe\n",
    "    # col: column to apply the operation\n",
    "    # op: operation to apply\n",
    "    # return: dataframe with the operation applied\n",
    "    df[col] = df[col].apply(op)\n",
    "    return df\n",
    "\n",
    "# Clean the code column\n",
    "cleanCodeOp = (lambda df, arg: applyToCol(df, arg, cleanCode))\n",
    "operateDFs(dict, cleanCodeOp, \"code\")\n",
    "\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look for duplicate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate code:  834\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate code: \", len(df1[\"code\"])-len(df1[\"code\"].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of entries with repeated code. However, if we drop duplicates we might lose information on student sessions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cmd_n rename\n",
    "\n",
    "Rename cmd_n so that it equals the predicate completed by the student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zKAYz8BCDmHKgNoSx</td>\n",
       "      <td>prop8</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>dvhCng5AdxC8MqjFy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8FmQ9PNWT2SXncTxX</td>\n",
       "      <td>prop10</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>5eT7wTw5kT8DwTbu2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eyGu5DYCrnk58G2fJ</td>\n",
       "      <td>prop7</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>niLmMRmm94Hz6ymcD</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbr9Aq6WfBLHrvE8</td>\n",
       "      <td>prop19</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>DnAm62D7JaqDzyy5y</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNegade3hLiutxCru</td>\n",
       "      <td>prop11</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>cjK4u23ZAfYm8fatA</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 _id   cmd_n  \\\n",
       "0  zKAYz8BCDmHKgNoSx   prop8   \n",
       "1  8FmQ9PNWT2SXncTxX  prop10   \n",
       "2  eyGu5DYCrnk58G2fJ   prop7   \n",
       "3  Akbr9Aq6WfBLHrvE8  prop19   \n",
       "4  MNegade3hLiutxCru  prop11   \n",
       "\n",
       "                                                code       derivationOf  sat  \n",
       "0  var sig File {var link : lone File}var sig Tra...  dvhCng5AdxC8MqjFy  1.0  \n",
       "1  var sig File {var link : lone File}var sig Tra...  5eT7wTw5kT8DwTbu2  1.0  \n",
       "2  var sig File {var link : lone File}var sig Tra...  niLmMRmm94Hz6ymcD  1.0  \n",
       "3  var sig File {var link : lone File}var sig Tra...  DnAm62D7JaqDzyy5y  1.0  \n",
       "4  var sig File {var link : lone File}var sig Tra...  cjK4u23ZAfYm8fatA  1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeExtraSuffix(pred):\n",
    "    return re.sub(\"OK|Ok|ok\", \"\", pred)\n",
    "\n",
    "remSuffixOp = (lambda df, arg: applyToCol(df, arg, removeExtraSuffix))\n",
    "operateDFs(dict, remSuffixOp, \"cmd_n\")\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Predicate Expression column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Java library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpype # Java\n",
    "\n",
    "# Import the Java libraries\n",
    "if not jpype.isJVMStarted():\n",
    "    jpype.startJVM(classpath=['lib/Parser/parser.jar'])\n",
    "\n",
    "# Import the Java classes\n",
    "Parser = jpype.JClass('org.higena.A4FParser')\n",
    "CompUtil = jpype.JClass('edu.mit.csail.sdg.parser.CompUtil')\n",
    "Reporter = jpype.JClass('edu.mit.csail.sdg.alloy4.A4Reporter')\n",
    "SyntaxError = jpype.JClass('edu.mit.csail.sdg.alloy4.ErrorSyntax')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate dataframes into separate dataframes for each predicate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9jPK8KBWzjFmBx4Hb ['prop1', 'prop2', 'prop3', 'prop4', 'prop5', 'prop6', 'prop7', 'prop8', 'prop9', 'prop10', 'prop11', 'prop12', 'prop13', 'prop14', 'prop15', 'prop16', 'prop17', 'prop18', 'prop19', 'prop20']\n",
      "FwCGymHmbqcziisH5 ['prop1', 'prop2', 'prop3', 'prop4', 'prop5', 'prop6', 'prop7', 'prop8', 'prop9', 'prop10', 'prop11', 'prop12', 'prop13', 'prop14', 'prop15', 'prop16', 'prop17', 'prop18']\n",
      "gAeD3MTGCCv8YNTaK ['undirected', 'oriented', 'acyclic', 'complete', 'noLoops', 'weaklyConnected', 'stonglyConnected', 'transitive']\n",
      "JC8Tij8o8GZb99gEJ ['Inv1', 'Inv2', 'Inv3', 'Inv4']\n",
      "jyS8Bmceejj9pLbTW ['Inv1', 'Inv2', 'Inv3', 'Inv4']\n",
      "PQAJE67kz8w5NWJuM ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10']\n",
      "sDLK7uBCbgZon3znd ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10']\n",
      "WGdhwKZnCu7aKhXq9 ['Inv1', 'Inv2', 'Inv3', 'Inv4']\n",
      "YH3ANm7Y5Qe5dSYem ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10', 'inv11', 'inv12', 'inv13', 'inv14', 'inv15']\n",
      "zoEADeCW2b2suJB2k ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7']\n",
      "zRAn69AocpkmxXZnW ['inv1', 'inv2', 'inv3', 'inv4', 'inv5', 'inv6', 'inv7', 'inv8', 'inv9', 'inv10', 'inv11', 'inv12', 'inv13', 'inv14', 'inv15']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>BTJstCSFzkYQBsQx6</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>29YEArmvK27JPiTia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>xkuuzm3We6L5nhycr</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>qCP5Z52W7HPyPhM66</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>9YjrCv4G59r5iMJ9Y</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>g3pdisnaMXvFwwdJH</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>EMz6E2zDEyB6JkAdX</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>ZA4XCBD3yxP9xNLRK</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id  cmd_n  \\\n",
       "166  BTJstCSFzkYQBsQx6  prop1   \n",
       "169  xkuuzm3We6L5nhycr  prop1   \n",
       "182  qCP5Z52W7HPyPhM66  prop1   \n",
       "255  g3pdisnaMXvFwwdJH  prop1   \n",
       "290  ZA4XCBD3yxP9xNLRK  prop1   \n",
       "\n",
       "                                                  code       derivationOf  sat  \n",
       "166  var sig File {var link : lone File}var sig Tra...  29YEArmvK27JPiTia  0.0  \n",
       "169  var sig File {var link : lone File}var sig Tra...  9jPK8KBWzjFmBx4Hb  1.0  \n",
       "182  var sig File {var link : lone File}var sig Tra...  9YjrCv4G59r5iMJ9Y  1.0  \n",
       "255  var sig File {var link : lone File}var sig Tra...  EMz6E2zDEyB6JkAdX  0.0  \n",
       "290  var sig File {var link : lone File}var sig Tra...  9jPK8KBWzjFmBx4Hb  0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parseChallenge(dict):\n",
    "    # Parse a challenge file\n",
    "    # dict: dictionary of dataframes\n",
    "    # return: the parsed challenges\n",
    "    parsed = {}\n",
    "    folder = \"data/challenges/\"\n",
    "\n",
    "    for challengeID, df in dict.items():\n",
    "        # Set file path\n",
    "        file = folder + challengeID + \".als\"\n",
    "        # Parse file\n",
    "        parsed[challengeID] = CompUtil.parseEverything_fromFile(Reporter(), None, file)\n",
    "\n",
    "    return parsed \n",
    "\n",
    "def genFunColumns(challenge):\n",
    "    # Generate a dictionary with the function names as keys and an empty list as value\n",
    "    # challenge: parsed challenge\n",
    "    # return: list of functions\n",
    "\n",
    "    columns = [] # Initialize dictionary\n",
    "    functions = challenge.getAllFunc() # Get all the functions\n",
    "\n",
    "    # Add the functions to the dictionary\n",
    "    for fun in functions:\n",
    "        if \"$$Default\" not in fun.label: # Ignore default pred\n",
    "            columns.append(str(fun.label).removeprefix(\"this/\"))\n",
    "    \n",
    "    return columns\n",
    "\n",
    "def separateDFbyPred(dict, parseChallenges):\n",
    "    # Separate the dataframes by predicate\n",
    "    # dict: dictionary of dataframes for each challenge\n",
    "    # parseChallenges: dictionary of parsed challenges\n",
    "    # return: dictionary of dataframes for each challenge and each predicate: dict[challenge][predicate]\n",
    "     \n",
    "    # Dictionary of dataframes for each exercise\n",
    "    allDfs = {}\n",
    "    # Iterate over the dataframes\n",
    "    for key, df in dict.items():\n",
    "        allDfs[key] = {} # init the challenge dictionary\n",
    "        challengePreds = list(genFunColumns(parseChallenges[key])) # Get the list of functions from the challenge\n",
    "        # Iterate over the exercises\n",
    "        for pred in challengePreds:\n",
    "            # Store the dataframe for the exercise\n",
    "            allDfs[key][pred] = df[df[\"cmd_n\"] == pred].copy()\n",
    "    \n",
    "    return allDfs\n",
    "\n",
    "\n",
    "parsedChallenges = parseChallenge(dict)\n",
    "allDfs = separateDFbyPred(dict, parsedChallenges)\n",
    "\n",
    "# Check\n",
    "for challenge, preds in allDfs.items():\n",
    "    print(challenge, list(preds.keys()))\n",
    "\n",
    "allDfs[\"9jPK8KBWzjFmBx4Hb\"][\"prop1\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Expr column that contains the expression written by the student to the respective predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR predicate  inv4  not found.\n",
      "ERROR predicate  inv4  not found.\n",
      "ERROR predicate  inv10  not found.\n",
      "ERROR predicate  inv10  not found.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>BTJstCSFzkYQBsQx6</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>29YEArmvK27JPiTia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no Trash and no Protected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>xkuuzm3We6L5nhycr</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>qCP5Z52W7HPyPhM66</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>9YjrCv4G59r5iMJ9Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>before no Trash + Protected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>g3pdisnaMXvFwwdJH</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>EMz6E2zDEyB6JkAdX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no Trash and no (Protected )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>ZA4XCBD3yxP9xNLRK</td>\n",
       "      <td>prop1</td>\n",
       "      <td>var sig File {var link : lone File}var sig Tra...</td>\n",
       "      <td>9jPK8KBWzjFmBx4Hb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>historically (no Trash and no Protected)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   _id  cmd_n  \\\n",
       "166  BTJstCSFzkYQBsQx6  prop1   \n",
       "169  xkuuzm3We6L5nhycr  prop1   \n",
       "182  qCP5Z52W7HPyPhM66  prop1   \n",
       "255  g3pdisnaMXvFwwdJH  prop1   \n",
       "290  ZA4XCBD3yxP9xNLRK  prop1   \n",
       "\n",
       "                                                  code       derivationOf  \\\n",
       "166  var sig File {var link : lone File}var sig Tra...  29YEArmvK27JPiTia   \n",
       "169  var sig File {var link : lone File}var sig Tra...  9jPK8KBWzjFmBx4Hb   \n",
       "182  var sig File {var link : lone File}var sig Tra...  9YjrCv4G59r5iMJ9Y   \n",
       "255  var sig File {var link : lone File}var sig Tra...  EMz6E2zDEyB6JkAdX   \n",
       "290  var sig File {var link : lone File}var sig Tra...  9jPK8KBWzjFmBx4Hb   \n",
       "\n",
       "     sat                                      expr  \n",
       "166  0.0                 no Trash and no Protected  \n",
       "169  1.0                                            \n",
       "182  1.0               before no Trash + Protected  \n",
       "255  0.0             no Trash and no (Protected )   \n",
       "290  0.0  historically (no Trash and no Protected)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getExpr(code: str, predicateID: str):\n",
    "    # Get the expression of a predicate\n",
    "    # code: string with the code\n",
    "    # predicateID: id of the predicate\n",
    "    # return: string with the expression of the predicate\n",
    "\n",
    "    reg = r\"pred \" + predicateID + r\"\\s?\\{(.*?)\\}\"\n",
    "    predicate = re.search(reg, code)\n",
    "\n",
    "    if predicate:\n",
    "        return predicate.group(1)\n",
    "    else:\n",
    "        print(\"ERROR predicate \", predicateID,  \" not found.\")\n",
    "        return None\n",
    "\n",
    "def genExprColumn(allDfs):\n",
    "    # Iterate over the challenges\n",
    "    for cmdDfs in allDfs.values():\n",
    "        # Iterate over the submission for each command\n",
    "        for cmd, df in cmdDfs.items():\n",
    "            df[\"expr\"] = df[\"code\"].apply(getExpr, args=(str(cmd),))\n",
    "           \n",
    "\n",
    "# Generate the expression column\n",
    "genExprColumn(allDfs)\n",
    "\n",
    "allDfs[\"9jPK8KBWzjFmBx4Hb\"][\"prop1\"].head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove submissions with errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>code</th>\n",
       "      <th>derivationOf</th>\n",
       "      <th>sat</th>\n",
       "      <th>cmd_n</th>\n",
       "      <th>expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_id, code, derivationOf, sat, cmd_n, expr]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop submissions with null expressions\n",
    "allDfs[\"zRAn69AocpkmxXZnW\"] = dropNulls(allDfs[\"zRAn69AocpkmxXZnW\"], \"expr\")\n",
    "\n",
    "# Check\n",
    "dfInv4 = allDfs[\"zRAn69AocpkmxXZnW\"][\"inv4\"]\n",
    "dfInv4[dfInv4[\"expr\"].isnull()].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add AST column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing  9jPK8KBWzjFmBx4Hb   prop1\n",
      "Parsing expression:  no Trash and no Protected\n",
      "Parsing expression:  \n",
      "Parsing expression:  before no Trash + Protected\n",
      "Parsing expression:  no Trash and no (Protected ) \n",
      "Parsing expression:  historically (no Trash and no Protected)\n",
      "Parsing expression:  \n",
      "Parsing expression:  historically no (Trash + Protected)\n",
      "Parsing expression:      no (Trash & Protected)  \n",
      "Parsing expression:  no Trash and no Protected\n",
      "Parsing expression:  historically no Trash + Protected\n",
      "Parsing expression:  always (no File and no Protected) \n",
      "Parsing expression:  no Trash and no Protected\n",
      "Parsing expression:  no Trash and no Protected\n",
      "Parsing expression:    no Trash and no Protected\n",
      "Parsing expression:    historically (once (no Trash & Protected))\n",
      "Parsing expression:  no Trash and no Protected\n",
      "Parsing expression:  no Trash + Protected\n",
      "Parsing expression:  historically no (Trash+Protected)\n",
      "Parsing expression:  no Trash and no (Protected & Trash) \n",
      "Parsing expression:  no (Trash+Protected)\n",
      "Parsing expression:      no (Trash+Protected)  no Trash and no Protected  \n",
      "Parsing expression:   no Trash + Protected\n",
      "Parsing expression:  no Trash + Protected\n",
      "Parsing expression:    no Trash and no Protected\n",
      "Parsing expression:  no Trash and no Protected\n",
      "Parsing expression:  no Trash + Protected\n",
      "Parsing expression:  no Trash + Protected\n",
      "Parsing expression:  no Trash and no Protected\n",
      "Parsing expression:    no Trash  no Protected\n",
      "Parsing expression:   no Trash and no Protected\n",
      "Parsing expression:  all f:File | f in Protected\n",
      "Parsing expression:  before { no Trash and no Protected\n"
     ]
    },
    {
     "ename": "edu.mit.csail.sdg.alloy4.ErrorSyntax",
     "evalue": "Syntax error at line 1 column 36:\nThere are 38 possible tokens that can appear here:\n! # ( * @ Int NAME NUMBER STRING String ^ after all always before disj eventually fun historically iden int let lone no none once one pred seq set some steps sum this univ { } ~ ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mA4FParser.java:12\u001b[0m, in \u001b[0;36morg.higena.A4FParser.parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Java Exception",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31medu.mit.csail.sdg.alloy4.ErrorSyntax\u001b[0m      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m             df[\u001b[39m\"\u001b[39m\u001b[39mast\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mexpr\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(parseExpr, args\u001b[39m=\u001b[39m(parseChallenges[challenge],))\n\u001b[0;32m     23\u001b[0m \u001b[39m# Add the ASTs columns\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m addASTsColumns(allDfs, parsedChallenges)\n\u001b[0;32m     26\u001b[0m \u001b[39m# Check\u001b[39;00m\n\u001b[0;32m     27\u001b[0m allDfs[\u001b[39m\"\u001b[39m\u001b[39m9jPK8KBWzjFmBx4Hb\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mprop1\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[31], line 21\u001b[0m, in \u001b[0;36maddASTsColumns\u001b[1;34m(allDfs, parseChallenges)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m cmd, df \u001b[39min\u001b[39;00m cmdDfs\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mParsing \u001b[39m\u001b[39m\"\u001b[39m, challenge, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, cmd)\n\u001b[1;32m---> 21\u001b[0m     df[\u001b[39m\"\u001b[39m\u001b[39mast\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mexpr\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(parseExpr, args\u001b[39m=\u001b[39;49m(parseChallenges[challenge],))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\apply.py:139\u001b[0m, in \u001b[0;36mApply.__init__.<locals>.f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m func(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[31], line 8\u001b[0m, in \u001b[0;36mparseExpr\u001b[1;34m(expr, parsedChallenge)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparseExpr\u001b[39m(expr, parsedChallenge):\n\u001b[0;32m      2\u001b[0m     \u001b[39m# Parse an expression\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[39m# expr: string with the expression\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[39m# parsedChallenge: parsed challenge module\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[39m# return: parsed expression\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mParsing expression: \u001b[39m\u001b[39m\"\u001b[39m, expr)\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39m(Parser\u001b[39m.\u001b[39;49mparse(expr, parsedChallenge))\n",
      "\u001b[1;31medu.mit.csail.sdg.alloy4.ErrorSyntax\u001b[0m: Syntax error at line 1 column 36:\nThere are 38 possible tokens that can appear here:\n! # ( * @ Int NAME NUMBER STRING String ^ after all always before disj eventually fun historically iden int let lone no none once one pred seq set some steps sum this univ { } ~ "
     ]
    }
   ],
   "source": [
    "def parseExpr(expr, parsedChallenge):\n",
    "    # Parse an expression\n",
    "    # expr: string with the expression\n",
    "    # parsedChallenge: parsed challenge module\n",
    "    # return: parsed expression\n",
    "    print(\"Parsing expression: \", expr)\n",
    "\n",
    "    return str(Parser.parse(expr, parsedChallenge))\n",
    "\n",
    "def addASTsColumns(allDfs, parseChallenges):\n",
    "    # Add the ASTs columns\n",
    "    # allDfs: dictionary of dataframes for each challenge and each predicate\n",
    "    # parseChallenges: dictionary of parsed challenges\n",
    "    # return: dictionary of dataframes for each challenge and each predicate with the ASTs columns\n",
    "\n",
    "    # Iterate over the challenges\n",
    "    for challenge, cmdDfs in allDfs.items():\n",
    "        # Iterate over the submission for each command\n",
    "        for cmd, df in cmdDfs.items():\n",
    "            print(\"Parsing \", challenge, \" \", cmd)\n",
    "            df[\"ast\"] = df[\"expr\"].apply(parseExpr, args=(parseChallenges[challenge],))\n",
    "\n",
    "# Add the ASTs columns\n",
    "addASTsColumns(allDfs, parsedChallenges)\n",
    "\n",
    "# Check\n",
    "allDfs[\"9jPK8KBWzjFmBx4Hb\"][\"prop1\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder:  ../graph/data/9jPK8KBWzjFmBx4Hb/\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop1.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop2.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop3.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop4.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop5.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop6.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop7.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop8.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop9.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop10.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop11.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop12.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop13.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop14.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop15.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop16.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop17.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop18.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop19.csv\n",
      "Exported 9jPK8KBWzjFmBx4Hb/prop20.csv\n",
      "Created folder:  ../graph/data/FwCGymHmbqcziisH5/\n",
      "Exported FwCGymHmbqcziisH5/prop1.csv\n",
      "Exported FwCGymHmbqcziisH5/prop2.csv\n",
      "Exported FwCGymHmbqcziisH5/prop3.csv\n",
      "Exported FwCGymHmbqcziisH5/prop4.csv\n",
      "Exported FwCGymHmbqcziisH5/prop5.csv\n",
      "Exported FwCGymHmbqcziisH5/prop6.csv\n",
      "Exported FwCGymHmbqcziisH5/prop7.csv\n",
      "Exported FwCGymHmbqcziisH5/prop8.csv\n",
      "Exported FwCGymHmbqcziisH5/prop9.csv\n",
      "Exported FwCGymHmbqcziisH5/prop10.csv\n",
      "Exported FwCGymHmbqcziisH5/prop11.csv\n",
      "Exported FwCGymHmbqcziisH5/prop12.csv\n",
      "Exported FwCGymHmbqcziisH5/prop13.csv\n",
      "Exported FwCGymHmbqcziisH5/prop14.csv\n",
      "Exported FwCGymHmbqcziisH5/prop15.csv\n",
      "Exported FwCGymHmbqcziisH5/prop16.csv\n",
      "Exported FwCGymHmbqcziisH5/prop17.csv\n",
      "Exported FwCGymHmbqcziisH5/prop18.csv\n",
      "Created folder:  ../graph/data/gAeD3MTGCCv8YNTaK/\n",
      "Exported gAeD3MTGCCv8YNTaK/undirected.csv\n",
      "Exported gAeD3MTGCCv8YNTaK/oriented.csv\n",
      "Exported gAeD3MTGCCv8YNTaK/acyclic.csv\n",
      "Exported gAeD3MTGCCv8YNTaK/complete.csv\n",
      "Exported gAeD3MTGCCv8YNTaK/noLoops.csv\n",
      "Exported gAeD3MTGCCv8YNTaK/weaklyConnected.csv\n",
      "Exported gAeD3MTGCCv8YNTaK/stonglyConnected.csv\n",
      "Exported gAeD3MTGCCv8YNTaK/transitive.csv\n",
      "Created folder:  ../graph/data/JC8Tij8o8GZb99gEJ/\n",
      "Exported JC8Tij8o8GZb99gEJ/Inv1.csv\n",
      "Exported JC8Tij8o8GZb99gEJ/Inv2.csv\n",
      "Exported JC8Tij8o8GZb99gEJ/Inv3.csv\n",
      "Exported JC8Tij8o8GZb99gEJ/Inv4.csv\n",
      "Created folder:  ../graph/data/jyS8Bmceejj9pLbTW/\n",
      "Exported jyS8Bmceejj9pLbTW/Inv1.csv\n",
      "Exported jyS8Bmceejj9pLbTW/Inv2.csv\n",
      "Exported jyS8Bmceejj9pLbTW/Inv3.csv\n",
      "Exported jyS8Bmceejj9pLbTW/Inv4.csv\n",
      "Created folder:  ../graph/data/PQAJE67kz8w5NWJuM/\n",
      "Exported PQAJE67kz8w5NWJuM/inv1.csv\n",
      "Exported PQAJE67kz8w5NWJuM/inv2.csv\n",
      "Exported PQAJE67kz8w5NWJuM/inv3.csv\n",
      "Exported PQAJE67kz8w5NWJuM/inv4.csv\n",
      "Exported PQAJE67kz8w5NWJuM/inv5.csv\n",
      "Exported PQAJE67kz8w5NWJuM/inv6.csv\n",
      "Exported PQAJE67kz8w5NWJuM/inv7.csv\n",
      "Exported PQAJE67kz8w5NWJuM/inv8.csv\n",
      "Exported PQAJE67kz8w5NWJuM/inv9.csv\n",
      "Exported PQAJE67kz8w5NWJuM/inv10.csv\n",
      "Created folder:  ../graph/data/sDLK7uBCbgZon3znd/\n",
      "Exported sDLK7uBCbgZon3znd/inv1.csv\n",
      "Exported sDLK7uBCbgZon3znd/inv2.csv\n",
      "Exported sDLK7uBCbgZon3znd/inv3.csv\n",
      "Exported sDLK7uBCbgZon3znd/inv4.csv\n",
      "Exported sDLK7uBCbgZon3znd/inv5.csv\n",
      "Exported sDLK7uBCbgZon3znd/inv6.csv\n",
      "Exported sDLK7uBCbgZon3znd/inv7.csv\n",
      "Exported sDLK7uBCbgZon3znd/inv8.csv\n",
      "Exported sDLK7uBCbgZon3znd/inv9.csv\n",
      "Exported sDLK7uBCbgZon3znd/inv10.csv\n",
      "Created folder:  ../graph/data/WGdhwKZnCu7aKhXq9/\n",
      "Exported WGdhwKZnCu7aKhXq9/Inv1.csv\n",
      "Exported WGdhwKZnCu7aKhXq9/Inv2.csv\n",
      "Exported WGdhwKZnCu7aKhXq9/Inv3.csv\n",
      "Exported WGdhwKZnCu7aKhXq9/Inv4.csv\n",
      "Created folder:  ../graph/data/YH3ANm7Y5Qe5dSYem/\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv1.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv2.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv3.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv4.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv5.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv6.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv7.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv8.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv9.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv10.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv11.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv12.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv13.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv14.csv\n",
      "Exported YH3ANm7Y5Qe5dSYem/inv15.csv\n",
      "Created folder:  ../graph/data/zoEADeCW2b2suJB2k/\n",
      "Exported zoEADeCW2b2suJB2k/inv1.csv\n",
      "Exported zoEADeCW2b2suJB2k/inv2.csv\n",
      "Exported zoEADeCW2b2suJB2k/inv3.csv\n",
      "Exported zoEADeCW2b2suJB2k/inv4.csv\n",
      "Exported zoEADeCW2b2suJB2k/inv5.csv\n",
      "Exported zoEADeCW2b2suJB2k/inv6.csv\n",
      "Exported zoEADeCW2b2suJB2k/inv7.csv\n",
      "Created folder:  ../graph/data/zRAn69AocpkmxXZnW/\n",
      "Exported zRAn69AocpkmxXZnW/inv1.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv2.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv3.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv4.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv5.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv6.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv7.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv8.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv9.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv10.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv11.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv12.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv13.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv14.csv\n",
      "Exported zRAn69AocpkmxXZnW/inv15.csv\n"
     ]
    }
   ],
   "source": [
    "def exportData(allDfs):\n",
    "    # Export the dataframes to csv files\n",
    "    # allDfs: dictionary of dataframes for each challenge and each predicate \n",
    "\n",
    "    path = \"../graph/data/\"\n",
    "\n",
    "    # Iterate over the challenges\n",
    "    for challenge, cmdDfs in allDfs.items():\n",
    "        # Create folder if it does not exist\n",
    "        folder = path + challenge + \"/\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            print(\"Created folder: \", folder)\n",
    "\n",
    "        # Iterate over the submission for each command\n",
    "        for cmd, df in cmdDfs.items():\n",
    "            # Export dataframe to csv\n",
    "            file = folder + cmd + \".csv\"\n",
    "            df.to_csv(file, index=False)\n",
    "            print(f\"Exported {challenge}/{cmd}.csv\")\n",
    "\n",
    "# Export the dataframes to db\n",
    "exportData(allDfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
